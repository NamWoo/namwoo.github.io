{"meta":{"title":"my Blog of Absolute and Subjective Knowledge","subtitle":"지극히 개인적이고 주관적이고 상대적이며 절대적인 나만의 블로그","description":"data scientist, biomedical Engineering","author":"Namwoo Kim","url":"http://namwoo.github.io"},"pages":[{"title":"schedule","date":"2019-01-16T20:36:08.000Z","updated":"2019-01-16T20:36:08.705Z","comments":true,"path":"schedule/index.html","permalink":"http://namwoo.github.io/schedule/index.html","excerpt":"","text":""},{"title":"All categories","date":"2019-01-16T20:35:57.000Z","updated":"2019-01-17T13:08:27.414Z","comments":false,"path":"categories/index.html","permalink":"http://namwoo.github.io/categories/index.html","excerpt":"","text":"categories: categoryA categoryB"},{"title":"All tags","date":"2019-01-16T20:35:38.000Z","updated":"2019-01-17T02:44:03.073Z","comments":false,"path":"tags/index.html","permalink":"http://namwoo.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"20190218_TIL","slug":"20190218-TIL","date":"2019-02-18T00:36:11.000Z","updated":"2019-02-18T00:37:33.783Z","comments":true,"path":"2019/02/18/20190218-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/18/20190218-TIL/","excerpt":"","text":"스스로가 꽤 진전이 있다고 생각했는데 아직도 전처리 중……","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190216_TIL","slug":"20190216-TIL","date":"2019-02-16T14:46:32.000Z","updated":"2019-02-16T14:46:44.758Z","comments":true,"path":"2019/02/16/20190216-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/16/20190216-TIL/","excerpt":"","text":"오늘도 안되는 날.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190215_TIL","slug":"20190215-TIL","date":"2019-02-15T14:49:22.000Z","updated":"2019-02-15T14:59:00.757Z","comments":true,"path":"2019/02/15/20190215-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/15/20190215-TIL/","excerpt":"","text":"아… 여전히 같은곳에서 맴도는.. 진도는 안나가고.. 흠. 맨땅에 해딩.. 계속 하는 수 밖에.. 그나저나 영어는..? 영어 한다고 넷플릭스 보냐?","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190214_TIL","slug":"20190214-TIL","date":"2019-02-14T13:19:47.000Z","updated":"2019-02-14T13:20:41.608Z","comments":true,"path":"2019/02/14/20190214-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/14/20190214-TIL/","excerpt":"","text":"프로젝트 시도중…… 진행은 어떻게 하겠는데 데이터 셋에 대한 이해도가 적으니 진전이 없다.. 이래서 도메인널리지 도메인 널리지 하는 건가? 도통 뭔 말인지… 에고","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"tooslow","slug":"tooslow","date":"2019-02-13T13:17:19.000Z","updated":"2019-02-13T13:18:59.451Z","comments":true,"path":"2019/02/13/tooslow/","link":"","permalink":"http://namwoo.github.io/2019/02/13/tooslow/","excerpt":"","text":"컴이 너무 느리다… 으아… 뭘 할 수가 없네.. 100메가짜리 csv 파일이 jupyter에서 그냥 코딩한거 휠 내리는 것도 이리 뚝뚝 끊기면 어쩌라는 거지.. 에효…","categories":[],"tags":[{"name":"Diary","slug":"Diary","permalink":"http://namwoo.github.io/tags/Diary/"}]},{"title":"20190213_TIL","slug":"20190213-TIL","date":"2019-02-13T02:56:40.000Z","updated":"2019-02-13T13:16:19.822Z","comments":true,"path":"2019/02/13/20190213-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/13/20190213-TIL/","excerpt":"","text":"Random Projection [Note: this lesson comes after a lesson explaining Principal Component Analysis] Paper: Random projection in dimensionality reduction: Applications to image and text data This paper examines using Random Projection to reduce the dimensionality of image and text data. It shows how Random Projection proves to be a computationally simple method of dimensionality reduction, while still preserving the similarities of data vectors to a high degree. The paper shows this on real-world datasets including noisy and noiseless images of natural scenes, and text documents from a newsgroup corpus. Paper: Random Projections for k-means Clustering This paper uses Random Projection as an efficient dimensionality reduction step before conducting k-means clustering on a dataset of 400 face images of dimensions 64 × 64. 차원 감소에 대해 설명. 첫번쨰 방법은 임의의 투영법, Random Projection. pCA보다 계산상 효율적이다. 데이터세트가 있는 경우 일반적으로 사용된다. PCA는 차원이 너무 많아 계산이 힘들다. PCA는 분산이 최대화 되는 벡터 또는 방향을 찾아서 차원을 줄이고 정보를 잃을 때 가장 적은 정보량을 잃게 된다. Random projection은 랜덤으로 그은 선에 투영된 점을 단순히 축소했다 할 수 있다. 이론적 배경은 데이터에 랜덤행렬을 곱한 것.Johnson-Lindenstrauss lemma 보조정리 Paper: “Independent component analysis: algorithms and applications” (pdf) nonGaussian 이어야한다. 어떻게? negentropy 엔트로피, 정보이론. 독립적.이어야 한다. Paper: Independent Component Analysis of Electroencephalographic Data [PDF] This paper is an example of how ICA is used to transform EEG scan data to do blind source separation. For example, on the left are the readings of 14 channels from an EEG scan that lasted 4.5 seconds. On the right are the independent components extracted from that dataset: Paper: Applying Independent Component Analysis to Factor Model in Finance [PDF]","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190212_TIL","slug":"20190212-TIL","date":"2019-02-11T17:05:55.000Z","updated":"2019-02-13T03:14:37.579Z","comments":true,"path":"2019/02/12/20190212-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/12/20190212-TIL/","excerpt":"","text":"“curse of dimensionality” https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/ https://elitedatascience.com/dimensionality-reduction-algorithms http://www.ai.mit.edu/projects/jmlr/papers/volume3/guyon03a/source/old/guyon03a.pdf This is a great post answering a number of common questions on PCA. A simple introduction of what PCA is aimed to accomplish is provided here in a simple example. A nice visual, and mathematical, illustration of PCA is provided in this video by 3 blue 1 brown. If you dive into the literature surrounding PCA, you will without a doubt run into the language of eigenvalues and eigenvectors. These are just the math-y words for things you have already encountered in this lesson. An eigenvalue is the same as the amount of variability captured by a principal component, and an eigenvector is the principal component itself. To see more on these ideas, take a look at the following three links below: A great introduction into the mathematics of principal components analysis. An example of using PCA in python by one of my favorite data scientists. An example of PCA from the scikit learn documentation. Where is PCA Used?In general, PCA is used to reduce the dimensionality of your data. Here are links to some specific use cases beyond what you covered in this lesson: PCA for microarray data. PCA for anomaly detection. PCA for time series data. If you ever feel overwhelmed by the amount of data you have, you can look to PCA to reduce the size of your dataset, while still retaining the maximum amount of information (though this does often come at the cost of reducing your data interpretability). They aim to capture the most amount of variability in the original dataset.They are orthogonal to (independent of) one another. https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190211_TIL","slug":"20190211-TIL","date":"2019-02-11T11:01:36.000Z","updated":"2019-02-11T11:08:58.436Z","comments":true,"path":"2019/02/11/20190211-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/11/20190211-TIL/","excerpt":"","text":"Link: Details of the Adjusted Rand index PDF Density-Based Clustering Validation PDF Cluster Validation Adjusted Rand Index Silhouette score PCA PCA를 이런 식으로 다시 접하니 또 새롭네.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190210_TIL","slug":"20190210-TIL","date":"2019-02-10T03:46:57.000Z","updated":"2019-02-10T12:35:49.069Z","comments":true,"path":"2019/02/10/20190210-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/10/20190210-TIL/","excerpt":"","text":"내가 작성한 문서 중에 자세한 그림과 정보는 사방팔방에서 긁어온 거니까 저작권상 빼고 직접 적은 내용만 옮겨 붙여넣기. 어쨌거나 저쩄거나 꼭 읽어봐야할 GMM 관련 논문들. GMMPaper: Nonparametric discovery of human routines from sensor data PDF Paper: Application of the Gaussian mixture model in pulsar astronomy PDF Paper: Speaker Verification Using Adapted Gaussian Mixture Models PDF Paper: Adaptive background mixture models for real-time tracking PDF Video: https://www.youtube.com/watch?v=lLt9H6RFO6A https://youtu.be/JNlEIEwe-Cg Applications 이 논문은 GMM을 활용해서 센서판독값을 이해하는 과정이다. 주머니에 들어있는 가속도계에서 들어오는 센서신호를 가지고 일상생활에서 어떤 행동이 어떠한 패턴이 있는지 판단하게 된다. GMM은 여기서 큰 장점이 된다. 대화할때, 점심, 저녁활동, 업무 일 때는 구별할 수 있다. 또 GPS 기반 속도계를 이용해 일상생활을 분석하는 과정을 보면 버스, 바이크, 지하철, 걷을 때를 구분지을 수 있다. 천문학에서는 Pulsar 별을 분류하기 위해 역시 Gaussian MM 모델을 사용했고 Speaker Verification Vusing Adapted Gaussian Mixture Model 생체인식 분야에서도 사용되고 있다. 이것은 사람들의 서명을 식별하는데도 사용되었다. 조금 더 멋진 방법은 컴퓨터 비전 분야에 많이 있는데 GMM을 이용해 배경을 탐지하는 방법이다. 스트리밍 영상에서 배경을 찾고 배경만 출력할 수 있는 방법이다. 마찬가지로 아래 논문 역시 GMM을 활용하는 방법인데 배경을 배경을 빼고 남은 움직이는 물체, 즉 사람을 식별하는 과정을 나타낸다.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190208_TIL","slug":"20190208-TIL","date":"2019-02-08T09:21:12.000Z","updated":"2019-02-10T03:48:07.960Z","comments":true,"path":"2019/02/08/20190208-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/08/20190208-TIL/","excerpt":"","text":"DBSCAN 하고 Gaussian Mixture Model (GMM) Clustering","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190207_TIL","slug":"20190207-TIL","date":"2019-02-07T12:46:31.000Z","updated":"2019-02-07T12:46:52.508Z","comments":true,"path":"2019/02/07/20190207-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/07/20190207-TIL/","excerpt":"","text":"클러스터링 이어서.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190206_TIL","slug":"20190206-TIL","date":"2019-02-06T12:22:23.000Z","updated":"2019-02-06T12:23:28.654Z","comments":true,"path":"2019/02/06/20190206-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/06/20190206-TIL/","excerpt":"","text":"오늘은 클러스터링 방법. single link clustering complete link clustering agglomerative clustering","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"unfamiliar","slug":"unfamiliar","date":"2019-02-05T23:54:41.000Z","updated":"2019-02-06T12:21:48.402Z","comments":true,"path":"2019/02/06/unfamiliar/","link":"","permalink":"http://namwoo.github.io/2019/02/06/unfamiliar/","excerpt":"","text":"익숙하지 않은 것들에 대해서새해, 친지와 가족 그리고 또 매형의 친구분까지, 다 같이 식사를 하면서 조언을 해주신다. 그리고 돌아오면서 마음먹었던 것들과 그리고 꼭 해보라고, 꼭 하라고 권해주시는 것들을 다시금 생각해본다. 모두가 익숙하지 않은 것들이고 내가 나만의 습관으로 만들기 어려운 것들 인것 같다. 내가 정말 꼭 습관으로 오랫동안 만들고 싶은 것들은 암기습관 뛰기(뒷산) 꾸준한 암기로 뇌세포를 활성화시키고 싶지만 외우는 것보다 논리정연하게 풀어 계산하고 수학, 그리고 과학처럼 원리와 개념적 이해로 넘어가며 정확한 답이 존재하는 것들에 흥미가 있기에… 그리고 런닝. 뜀박질. 아침마다 나가서 동네 한바뀌 뛰고싶은데.. 그게 마음처럼 잘 안되는 것 같다. 딱 우리집 아파트 우리동에서 출발하면 20분만 걸으면 관악산 봉우리 삼성산 정상에 닿는데 그걸 잘 안한다. 그리고 매형친구분께서 꼭 하라고, 제발 좀 하라고 하는 것들 만남(여자) 골프 나보고 문제있다고 오해받을 수 있단다.. 아니 여자도 없고 주변에 여자도 없는게 말이 되느냐고 이따 친구들(죄다남자) 만나러 간다니까 가지 말란다. ㅋㅋㅋ…….ㅠㅠ 뭔가 웃픈 이야기인건지.. 내가 문제가 있는건지 주변에 편하게 연락해서 볼 수 있는 이성친구가 단 한명이 없다. 꽤 오래됐고 아니 항상 이었고… 별로 그게 불편하거나 문제라고 생각하지도 않았다. 외롭다고 생각한 적도 없고 말이다. 단지 나이가 한 살 한 살 들어가면서 조금씩 주변에서 얘기하는 것들이 많아지는 것일 뿐. 골프는 솔직히 별로 좋아하진 않는다. 일단 재미가 없다. 골프가 운동? 필드를 걷는게 운동이라니 말이 안된다. 골프, 당구, 볼링 같은 정적인 운동을 할바엔 앉아서 텍사스홀덤을 치는걸 더 좋아하고 탁구나 차라리 등산, 런닝을 해서 심폐지구력을 올릴 것이다. 하지만.. 볼링을 배우려고 볼 사는것 보다 차라리 골프를 배우는게 더 재밌을 것 같고 나아보이니 조만간에 스크린부터 시작해야지 결국 위에 4가지를 올해 설 첫날 다짐한 것들이니 지킬 수 있을까? 단어암기 꾸준히 하루에 몇 개씩이라도 최소한으로 외우고 꾸준히 뒷산을 오르내리며 사귀지 않더라도 최소한 휴대폰에 연락할 수 있는 이성친구 만들기 아니면 모임이라도 들어가기 그리고 골프! 할 수 있을까? 꼭 해야지. 무조건 해야지. 오늘 2019년 2월6일. 다음에 오는 일주일 후 수요일엔 스스로 약속을 지킬 수 있기를.","categories":[],"tags":[{"name":"Diary","slug":"Diary","permalink":"http://namwoo.github.io/tags/Diary/"}]},{"title":"20190205_TIL","slug":"20190205-TIL","date":"2019-02-05T12:44:15.000Z","updated":"2019-02-05T14:16:43.468Z","comments":true,"path":"2019/02/05/20190205-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/05/20190205-TIL/","excerpt":"","text":"TIL을 쓰고 또 중복해서 각각의 프로젝트 파일에 정리하고 또 그걸 나눠서 강좌마다 써야하니 중복이 너무 심하다. 다른 사람들처럼 TIL폴더에 각 언어마다 쌓아가는걸로 하기엔 기준이 되는 내 지식이 부족해 그것도 아닌것 같고, 그냥 그날 배운 내용을 정리해서 써넣고 그 내용을 복붙해서 프로젝트로 옮기기에도 내용상 공개가 꺼리는 것들이 많은, public 폴더용이기 때문에 그냥 요약이나 중요했던, 또는 몰랐던 질문거리 내용식으로 적어야겠다. 아마 1달에서 2달 뒤에 정리하는 과정이 다 끝나고 나면 TIL 폴더를 아예 따로 뽑아서 각 언어 폴더를 하층구조로 쌓아나아가야겠다. 오늘 배운건. unsupervised learning single link 이론 및 실습.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190204_TIL","slug":"20190204-TIL","date":"2019-02-04T14:54:57.000Z","updated":"2019-02-04T14:55:40.951Z","comments":true,"path":"2019/02/04/20190204-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/04/20190204-TIL/","excerpt":"","text":"자꾸 오류가 나네","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190202_TIL","slug":"20190202-TIL","date":"2019-02-01T23:37:51.000Z","updated":"2019-02-02T05:03:02.748Z","comments":true,"path":"2019/02/02/20190202-TIL/","link":"","permalink":"http://namwoo.github.io/2019/02/02/20190202-TIL/","excerpt":"","text":"비지도학습, Unsupervised Learning, Clustering, Feature Scaling 데이터 만들기넘파이 모듈을 사용해 원하는 데이터의 형태를 정의할 수 있다. refer numpy.random.RandomState(seed = None)123import numpy as npn_points = 100X = np.random.RandomState(3200000).uniform(-3, 3, [n_points, 2]) seed = 3200000 설정해주면 랜덤으로 나오는 데이터가 다음에 실행해도 또 다음에 실행해도 같은 랜덤값으로 출력되게 해준다. 그래서 실습할 때나 테스트 할 때, 또 다른 사람에게 확인할 때 항상 다른 데이터가 아닌 같은 랜덤데이터가 출력 될 수 있도록 해준다. uniform(low, high, size) low, high, size 의 파라메터가 정의되며 위 코드에선 -3부터 3까지의 숫자가 100x2 행렬로 랜덤으로 생성되게끔 한다. numpy.absolute()1X_abs = np.absolute(X) numpy.absolute(x, /, out=None, *, where=True, casting=&#39;same_kind&#39;, order=&#39;K&#39;, dtype=None, subok=True[, signature, extobj]) = &lt;ufunc &#39;absolute&#39;&gt; 딱히 다른 파라메터는 필요없는거 같고 수학적 정의 그대로 음수를 양수로 바꿔주는 절대값 함수. 123456&gt;&gt;&gt; x = np.array([-1.2, 1.2])&gt;&gt;&gt; np.absolute(x)array([ 1.2, 1.2])&gt;&gt;&gt; np.absolute(1.2 + 1j)1.5620499351813308 logical_and그리고 다양한 논리함수들. np doc에 자세한 설명과 예제까지. 123456789&gt;&gt;&gt; np.logical_and(True, False)False&gt;&gt;&gt; np.logical_and([True, False], [False, False])array([False, False])&gt;&gt;&gt; x = np.arange(5)&gt;&gt;&gt; np.logical_and(x&gt;1, x&lt;4)array([False, False, True, True, False]) logical_or123456789&gt;&gt;&gt; np.logical_or(True, False)True&gt;&gt;&gt; np.logical_or([True, False], [False, False])array([ True, False])&gt;&gt;&gt; x = np.arange(5)&gt;&gt;&gt; np.logical_or(x &lt; 1, x &gt; 3)array([ True, False, False, False, True]) logical_not123456789&gt;&gt;&gt; np.logical_not(3)False&gt;&gt;&gt; np.logical_not([True, False, 0, 1])array([False, True, True, False])&gt;&gt;&gt; x = np.arange(5)&gt;&gt;&gt; np.logical_not(x&lt;3)array([False, False, False, True, True]) logical_xorbitwise_and종합1234567891011121314151617181920212223242526272829303132333435def create_data(): n_points = 120 X = np.random.RandomState(3200000).uniform(-3, 3, [n_points, 2]) X_abs = np.absolute(X) inner_ring_flag = np.logical_and(X_abs[:,0] &lt; 1.2, X_abs[:,1] &lt; 1.2) outer_ring_flag = X_abs.sum(axis = 1) &gt; 5.3 keep = np.logical_not(np.logical_or(inner_ring_flag, outer_ring_flag)) X = X[keep] X = X[:60] # only keep first 100 X1 = np.matmul(X, np.array([[2.5, 0], [0, 100]])) + np.array([22.5, 500]) plt.figure(figsize = [15,15]) plt.scatter(X1[:,0], X1[:,1], s = 64, c = plot_colors[-1]) plt.xlabel('5k Completion Time (min)', size = 30) plt.xticks(np.arange(15, 30+5, 5), fontsize = 30) plt.ylabel('Test Score (raw)', size = 30) plt.yticks(np.arange(200, 800+200, 200), fontsize = 30) ax = plt.gca() ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) [side.set_linewidth(2) for side in ax.spines.values()] ax.tick_params(width = 2) plt.savefig('C18_FeatScalingEx_01.png', transparent = True) data = pd.DataFrame(X1) data.columns = ['5k_Time', 'Raw_Test_Score'] return data 파라메터 추가해서 시간하고 분에따라 graph title 달라지게 수정해야겠음.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190129_TIL","slug":"20190129-TIL","date":"2019-01-29T11:21:33.000Z","updated":"2019-01-29T14:00:14.238Z","comments":true,"path":"2019/01/29/20190129-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/29/20190129-TIL/","excerpt":"","text":"너무 졸리지만.. 일단 어제 오늘 배운 내용을 적어놓자. 유인물과 노트필기에 해놓은 내용은 나중에 차차 채워놓고 머릿속에 있는 내용들을 까먹기 전에 적어보자. HPC 교육 KISTI 한국과학기술정보연구원(대전본원), 대전 카이스트 바로 옆 교육: 5호기 슈퍼컴퓨터 활용 2019년 1월 28일 월요일 오전 9시30분 ~ 오후 4시30분 (1일 과정) 교육: 시스템운영 (System Operation) 2019년 1월 29일 ghk요일 오전 9시30분 ~ 오후 4시30분 (1일 과정) HPC 내용정리 슈퍼컴퓨터=HPC=High Performance computer 라는 개념이 모호하다는 점 일반 범용컴퓨터도 슈퍼컴퓨터에 근접하는 고성능으로 접근해오고 있다는 점 국내 500억원대 슈퍼컴퓨터 양대산맥은 기상청과 한국과학기술정보연구원 단 둘 기상청은 컴퓨터를 나눠 반반씩만 사용중(지진 같은 천재지변 대비) 단일장비로는 한국과학기술정보연구원 이하 KISTI가 압도적. 그 밑으로는 10억원 이하 사이즈(현대중공업 등 십여곳 정도 운영 중) 거의 대부분 Intel Xeon Phi CPU 모델을 사용한다. 일반적으로 우리가 사용하는 가정용 또는 연구개발용 컴퓨터의 CPU는 Intel i5, i7 같은 비싼거 35만, 40만 이런 CPU엔 core가 8개가 들어있다. 내가 쓰는 Intel i5 4670은 코어가 4개…. Intel Xeon Phi CPU는 코어가 68개.. 최근껀 72개…..속도, 성능 모두 압도적.. 이 CPU와 함께 한 컴퓨터에 96GB DDR 램에 + 16GB MDCRAM 까지..이 모든 것이 한 컴퓨터 즉 한 노드고 이 노드들이 8305대가 붙어있다…. 그러니 500억이 넘어가는… 우리가 가정에서 쓸 수 있는 Intel Xeon Skylake CPU도 20코어로 한 노드에 2개씩 램을 192GB씩인 컴퓨터 132개가 더 붙어있다. … 이렇게 수천개의 컴퓨터가 모여서 병렬로 한대의 컴퓨터처럼 사용하게 하는 기기에는 통신문제, 성능문제도 옵티마이징해줘야하고(이게 MPP) 그냥 모아놓으면 클러스터, 각 노드별로 그러니까 각각의 8천대의 컴퓨터별로 역할을 나눠주고 관리해줘야하며 여러명이 동시에 사용하기 떄문에 작업스케줄이라는 프로그램으로 사용자들이 명령한 작업의 순서를 정해주고 노드별로 나눠주고 실행하는 PBS job Scheduler 가 필요하다. 슈퍼컴퓨터 누리온에 접속후 $ module av 로 사용가능한 module들을 확인하고 KNL인지 cray인지 또는 intel의 skylake인지 모듈 불러오고 $ module add craype-mic-knl 그 모듈에 맞는 컴파일러도 불러오고 $ module add intel/18.0.3 impi/18.0.8 $ icc -xxMIC-AVX512 source.c -o executable.x PBS 코딩 설정 qsub 작업제출 cat .. 결과확인 qstat 수행중인 전체 작업조회 qstat -u “myid” id가 진행중인 작업조회 qstat -x 끝난 작업확인 qstat -xf “myid” 끝난 작업 상세확인 ….. 새롭게 알게된 것들은 리눅스를 공부해야겠다는 것 Intel Xeon Phi vs. NVIDIA GPU 접근하는 모델에 따라 성능차이가 각각 다르다는 점. 슈퍼컴퓨터니까, 노드가 8천400개가 넘어가니까, 어마어마한 컴퓨터가 병렬로 8400대 이상 붙어있으니까 당연히 5호기 슈퍼컴퓨터 활용 교육","categories":[],"tags":[{"name":"HPC","slug":"HPC","permalink":"http://namwoo.github.io/tags/HPC/"},{"name":"KISTI","slug":"KISTI","permalink":"http://namwoo.github.io/tags/KISTI/"},{"name":"Supercomputer","slug":"Supercomputer","permalink":"http://namwoo.github.io/tags/Supercomputer/"},{"name":"Diary","slug":"Diary","permalink":"http://namwoo.github.io/tags/Diary/"}]},{"title":"20190128_TIL","slug":"20190128-TIL","date":"2019-01-29T11:21:25.000Z","updated":"2019-01-29T12:07:15.382Z","comments":true,"path":"2019/01/29/20190128-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/29/20190128-TIL/","excerpt":"","text":"카이스트 바로 옆에 있는 한국과학기술정보연구원으로 HPC(슈퍼컴퓨터) 활용교육을 받으러 가기까지는 많은 단계와 시간이 걸렸다. Machine Learning, Deep Learning, 그리고 각종 model들의 비교분석을 진행중에 느끼는 Computing power의 한계. 자연스럽게 CPU에서 GPU로, 개인컴에 GTX1060 2Gb로 CUDA 활용의 한계. 2Gb로는 아무것도 할 수가 없다 colab google 과 같은 클라우드 시스템의 관심 병렬프로세싱에 대한 관심 병렬의 한계와 GPU의 비교의 호기심 자연스럽게 넘어가는 과연 더 좋은 더 효율적인 컴퓨터에 대한 관심 범용컴퓨터와 슈퍼컴퓨터의 차이가 별로 없다고? 그렇다면 슈퍼컴퓨터란? HPC란? 무료교육이 있다고? 당장 고고싱 총 이틀, 각각 다른 과정이었는데 월요일은 슈퍼컴퓨터의 활용과 실습 화요일은 슈퍼컴퓨터의 관리와 운영 둘다 너무 유익했고 새로웠고 재밌었고 또 기회가 있다면 서울에서 차로 2시간반, 대중교통으론 3시간 걸려도 또 오고싶다는 거. 원래는 하루만 하는 줄 알았고 당연히 하루 당일치기로 왔다 가려했는데 수업중 다음날 수업도 있고 다른 교육이라고 하길래 당장 숙소를 잡고 하루 더 교육듣고 집으로! 숙소 들어가면 바로 기절해서 잠들고 새벽에 엄청 일찍 깨버릴것 같아서 수업 끝나고 극장가서 영화 한 편 보고 들어가 그대로 잠들었다. 근데 수면장애인지 너무 잘 잤다 생각하고 깼더니 10시고 또 눈떠보니 너무 오래잔거 같아 시계보니 1시.. 설마 다음날 오후 1시? ….. 그냥 새벽 한시… 겨우 4시간 잠든.. 그것도 여러번 깨고……. 다시 잠청하니 잠은 안오고… 아마 3시쯤.. 또 잠들었으려나… 그리고 또 6시 반에…. 일어난…. 에효. 보람차게 이틀날도 수업듣고 바로 집으로 와서 몰아서 글을 쓴다. 자세한 내용은 내일 일기에. 어? 그러고 보니 이건 TIL이 아니잖아….","categories":[],"tags":[{"name":"HPC","slug":"HPC","permalink":"http://namwoo.github.io/tags/HPC/"},{"name":"KISTI","slug":"KISTI","permalink":"http://namwoo.github.io/tags/KISTI/"},{"name":"Supercomputer","slug":"Supercomputer","permalink":"http://namwoo.github.io/tags/Supercomputer/"},{"name":"Diary","slug":"Diary","permalink":"http://namwoo.github.io/tags/Diary/"}]},{"title":"whatareyoudoingnow","slug":"whatareyoudoingnow","date":"2019-01-26T20:31:17.000Z","updated":"2019-01-26T20:32:13.858Z","comments":true,"path":"2019/01/27/whatareyoudoingnow/","link":"","permalink":"http://namwoo.github.io/2019/01/27/whatareyoudoingnow/","excerpt":"","text":"너 뭐했니? 뭐하고 있는거니? 빨리 정신차려.","categories":[],"tags":[{"name":"Diary","slug":"Diary","permalink":"http://namwoo.github.io/tags/Diary/"}]},{"title":"20190123_TIL","slug":"20190123-TIL","date":"2019-01-23T11:15:39.000Z","updated":"2019-01-23T11:19:49.215Z","comments":true,"path":"2019/01/23/20190123-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/23/20190123-TIL/","excerpt":"","text":"## install_from_swirl(“Exploratory Data Analysis”)","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"},{"name":"R","slug":"R","permalink":"http://namwoo.github.io/tags/R/"}]},{"title":"20190122_Letter_of_apology","slug":"20190122-Letter-of-apology","date":"2019-01-22T10:11:14.000Z","updated":"2019-01-22T10:11:14.246Z","comments":true,"path":"2019/01/22/20190122-Letter-of-apology/","link":"","permalink":"http://namwoo.github.io/2019/01/22/20190122-Letter-of-apology/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"20190122_TIL","slug":"20190122-TIL","date":"2019-01-22T10:09:46.000Z","updated":"2019-01-23T02:54:58.150Z","comments":true,"path":"2019/01/22/20190122-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/22/20190122-TIL/","excerpt":"","text":"RCoursera 에 Johns Hopkins University에서 만든 Data Science specialization 과정을 진행중인데 R 버전이 낮아 실습 패키지 실행이 안된다. 업뎃을 해보자. R studio에서 R 업데이트 R studio라면 sessionInfo() 로 버전 확인. 버전확인하는 방법 많음 R studio에서 직접은 안되고 R Gui로 가서 업뎃해야 한단다. R gui에서 12install.package(\"installr\"); library(installr)updateR() swirl package 업데이트그 다음 그냥 기본 library(swirl) 에는 Manipulating Data with dplyr Grouping and Chaining with dplyr Tidying Data with tidyr 이러한 과정이 없다. (Week3: Getting and Cleaning Data) 추가설치를 하려면 R Studio에서 1234library(swirl)uninstall_all_courses()install_course(\"Getting and Cleaning Data\")swirl() ref 잘 된다~","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"},{"name":"R","slug":"R","permalink":"http://namwoo.github.io/tags/R/"}]},{"title":"20190121_TIL","slug":"20190121-TIL","date":"2019-01-20T15:46:20.000Z","updated":"2019-01-21T11:21:24.635Z","comments":true,"path":"2019/01/21/20190121-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/21/20190121-TIL/","excerpt":"","text":"과제를 제출했는데 몇가지 코멘트가 달렸다. 그중 하나가 Even though your code is technically correct, the goal here is to implement the process manually, rather than using Transforms. You need to Find the ratio between the larger side and the smaller side Resize smaller side to 256 and larger side to 256*ratio Crop to 224 by 224, making sure the image is centered Convert to numpy and normalize 이걸 보고 읭? 왜? transforms.Compose 로 묶어 처리하면 안좋은 건가? 싶기도 했지만 저 라이브러리가 없을 때 해결하는 방법을 배워보라는 건지 아니면 실제 코딩이 어떻게 돌아가는지 확인해보라는 건지 싶기도 하고 해서 싹… 바꿔봤다. transforms.Compose이런 식으로 transforms을 사용하면 편하지만 https://pytorch.org/docs/stable/torchvision/transforms.html 방법11234567891011121314151617adjustments = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])image_pil = adjustments(image_np)``` transforms 함수를 사용하지 않고 수동으로 코딩하는 방법은 .. 일단 검색.. 시작..### 방법2```pythontrans = transforms.ToPILImage()trans1 = transforms.ToTensor()image_pil = trans(trans1(image_np)) ref to implement the process manually하나씩 찾아보고 고쳐가보자. transforms.Resize 바꾸기1234567891011# Resizefrom PIL import Imageresize_num = 256if image_pil.size[0] &gt; image_pil.size[1]: print('height' , image_pil.size[0], '&gt;' , 'width', image_pil.size[1]) print('height' , resize_num*image_pil.size[0]/image_pil.size[1], '&gt;' , 'width ', resize_num,' (resized)') image_pil = image_pil.resize((round(resize_num*image_pil.size[0]/image_pil.size[1]), resize_num)) else: print('height' , image_pil.size[0], '&lt;' , 'width', image_pil.size[1]) print('height ',resize_num,'&lt; width',resize_num*image_pil.size[1]/image_pil.size[0], '(resized)') image_pil = image_pil.resize((resize_num, round(resize_num*image_pil.size[1]/image_pil.size[0]))) 일단 이렇게 코딩하고 보니까 조금 복잡해보인다. w, h = image_pil.size 이렇게 퉁쳐서 image_pil.size[0] 가 w로 image_pil.size[1] 를 h로 하면 더 가독성이 좋을 것 같다. from PIL import Image 를 사용한 이유는 어차피 그래프를 그려줘야하니까 포함되어 있는 걸 최대한 사용했다. https://076923.github.io/posts/Python-opencv-8/https://kolikim.tistory.com/57 transforms.CenterCrop 바꾸기123456789from PIL import Image# CenterCropcrop_num = 224left = (image_pil.size[0] - crop_num)/2top = (image_pil.size[1] - crop_num)/2right = (image_pil.size[0] + crop_num)/2bottom = (image_pil.size[1] + crop_num)/2image_pil = image_pil.crop((left, top, right, bottom))# print(image_pil.size) reference1reference2 그냥.. 함수고 파라메터 넣는 수학계산이지 뭐 transforms.ToTensor 바꾸기기본적으로 PIL Image 나 numpy.ndarray 는 배열이 (H x W x C) 에 범위가 [0, 255] 이다. 이걸 Torch로 계산하기 위해 Torch에 맞게 바꿔줘야 하는게 Torch는 (C x H x W) 에 범위가 [0.0, 1.0] 이기 때문이다. 그래서 이름이 ToTensor, 텐서형식으로 바꾸기. PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] 1 2 0 to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] 201 120 C는 채널. 주로 RGB 색상정보 H는 이미지의 height 높이(위아래) W는 weight 이미지의 폭(양옆) 12image_np = np.array(image_pil) # (224, 224, 3)image_np = np.transpose(image_np, (2, 0, 1)) # (3, 224, 224) (H x W x C)를 (C x H x W)로 잘 바꿨는데 뭔가 이상하다. 변환은 잘 됐는데 transforms.ToTensor()에서 나온 결과값하고 다르다. 왜그러지? 일단 패쓰. 어쨌든 np.array 로 array 만들어주고 난 다음 np.transpose를 통해서 원래 순서인 0 1 2 인 행렬순서를 2 0 1로 바꿨다. 파라메터 순서는 기본적으로 입력된 0 1 2 순서대로, 여기선 (H x W x C)로 (224, 224, 3) 설정되어 있는 상태를 (C x H x W) 순으로 2 0 1 순서로 바꿔주면 (3, 224, 224) 요로코롬 바뀐다. https://github.com/pytorch/vision/issues/399 transforms.Normalize 바꾸기Normalize라는게 이미지 데이터 정보를 바꿔준다는 말인데 실제 0~255로 되어있는 컬러채널을 -1에서1 로 바꿔준다든가 중앙값, 평균값을 원하는 값으로 수정한다든가 한쪽으로 기울어져 있는 이미지 데이터 정보를 콤푸타가 잘 알아먹을 수 있고 쏠려서 학습하는 오류를 피하기 위해 해야한다고 한다. https://discuss.pytorch.org/t/question-about-inception-v3-model/8727 가장 좋은 Normalize 설명https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc Image processing with Python and SciPy http://prancer.physics.louisville.edu/astrowiki/index.php/Image_processing_with_Python_and_SciPy 이미지 다루는 설명https://www.oreilly.com/library/view/programming-computer-vision/9781449341916/ch01.html transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) 의 의미는 input[channel] = (input[channel] - mean[channel]) / std[channel] mean=[0.485, 0.456, 0.406]std=[0.229, 0.224, 0.225]img[c] = (img[c] - mean[c]) / std[c] 12345678910# Normalize1# image_normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])# image_pil = image_normalize(image_np).float()# Normalize2## std * image_np + mean# print(image_np[0,:,:])# image_np[0,:,:] = (image_np[0,:,:] - 0.485) / 0.229# image_np[0,:,:] = 0.229 * image_np[0,:,:] + 0.485 https://discuss.pytorch.org/t/understanding-transform-normalize/21730 sklearn.preprocessing.normalize 사용, np.atleast_1d 사용 https://stackoverflow.com/questions/21030391/how-to-normalize-an-array-in-numpy scale size minmaxscaler 사용 https://code.i-harness.com/en/q/1a7971 normalization-in-the-mnist-example https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/13 Normalization layers https://lasagne.readthedocs.io/en/latest/modules/layers/normalization.html Normalization 0-1 https://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range Normalization certain-range https://stackoverflow.com/questions/1735025/how-to-normalize-a-numpy-array-to-within-a-certain-range OpenCV-normalize http://swprog.tistory.com/entry/OpenCV-normalize https://forums.fast.ai/t/images-normalization/4058/9 123456789101112import numpy as npa = np.random.rand(3,2)# Normalised [0,1]b = (a - np.min(a))/np.ptp(a)# Normalised [0,255] as integerc = (255*(a - np.min(a))/np.ptp(a)).astype(int)# Normalised [-1,1]d = 2*(a - np.min(a))/np.ptp(a)-1 Normalize input image per color channel #338 https://github.com/onnx/onnx-coreml/issues/338https://github.com/onnx/onnx-coreml/issues/338https://github.com/onnx/onnx-coreml/issues/338 # IMAGE_NET_MEAN = [0.485, 0.456, 0.406] # IMAGE_NET_STD = [0.229, 0.224, 0.225] scale = 1.0 / (0.226 * 255.0) red_scale = 1.0 / (0.229 * 255.0) green_scale = 1.0 / (0.224 * 255.0) blue_scale = 1.0 / (0.225 * 255.0) args = dict(is_bgr=False, red_bias = -(0.485 * 255.0) , green_bias = -(0.456 * 255.0) , blue_bias = -(0.406 * 255.0)) https://stackoverflow.com/questions/50239066/efficiently-standardizing-images-in-a-numpy-array Pytorch Notes Data Augmentation Transfer Learning_1 Transfer Learning_2 Specific to this flower classification problem: Flower Classication_1 Flower Classication_2 Use if name == “main”: to make your script execuatble. From stackoverflow From thepythonguru","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190120_TMQ","slug":"20190120-TMQ","date":"2019-01-20T14:30:02.000Z","updated":"2019-01-20T14:30:02.995Z","comments":true,"path":"2019/01/20/20190120-TMQ/","link":"","permalink":"http://namwoo.github.io/2019/01/20/20190120-TMQ/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"20190120_TIL","slug":"20190120-TIL","date":"2019-01-19T20:52:14.000Z","updated":"2019-01-21T11:20:48.596Z","comments":true,"path":"2019/01/20/20190120-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/20/20190120-TIL/","excerpt":"","text":"자. 오늘도 하나씩. 일단. 오늘 예정은 프로젝트 제출건 코멘트 해결 Coursera 정리 유 초, 유 말 정리 Project Comment 정리Project 2: Create Your Own Image Classifier Comment1 흩어져 있는 import 모으기 딱 하나 떨어져 있었는데 이건 그냥 def 로 정의하는 느낌으로 다가 한거였는데… 음.. 해결 num_workers 쓸 수 있으면 쓰라고 했었네? 오호. 오류뜸. 안됨. 차선책으로 pin_memory=True num_workers and pin_memoryWhen to set pin_memory to true? https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723 How to Optimize Data Transfers in CUDA C/C++ https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/ How to Optimize Data Transfers in CUDA C/C++ https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/ https://github.com/NVIDIA-developer-blog/code-samples/blob/master/series/cuda-cpp/optimize-data-transfers/bandwidthtest.cu 왜 안되는지 모르겠고 저기서 말하는 num_workers 뜻도 아직 잘 모르겠다. CPU 프로세서 동시 구동하는 갯수인건지.. 멀티프로세싱할 수 있는 갯수 말하는 건지.. 일단 넘기고 다시 해야지… 하지만 pin_memory=True 는 잘 된다. 속도가 빠른지 느려진지는 전혀 모르겠지만… model selectionmodel = getattr(models, arch)(pretrained=True) 이렇게 쉬운 방법이 있었는데 몰랐다니… https://docs.python.org/3/library/functions.html getattr(object, name[, default])Return the value of the named attribute of object. name must be a string. If the string is the name of one of the object’s attributes, the result is the value of that attribute. For example, getattr(x, &#39;foobar&#39;) is equivalent to x.foobar. If the named attribute does not exist, default is returned if provided, otherwise AttributeError is raised. 12getattr(x, 'foobar')x.foobar setattr(object, name, value)This is the counterpart of getattr(). The arguments are an object, a string and an arbitrary value. The string may name an existing attribute or a new attribute. The function assigns the value to the attribute, provided the object allows it. For example, setattr(x, &#39;foobar&#39;, 123) is equivalent to x.foobar = 123. 12setattr(x, 'foobar', 123)x.foobar = 123 앞으로 유용하게 사용할듯. python Image resize 파이썬 이미지 크기조정출처 12345from PIL import Imageimage = Image.open(&apos;./1.jpg&apos;)resize_image = image.resize((512,512))resize_image.save(&apos;./2.jpg&apos;) https://code.i-harness.com/ko-kr/q/42e1a 12345new_width = 680new_height = new_width * height / width new_height = 680new_width = new_height * width / heightimg = img.resize((new_width, new_height), Image.ANTIALIAS) https://gist.github.com/agalea91/12149be6d4f64ba61c7b1d222fce3174 1234567891011121314151617181920212223242526def resize(img_path, max_px_size, output_folder): with Image.open(img_path) as img: width_0, height_0 = img.size out_f_name = os.path.split(img_path)[-1] out_f_path = os.path.join(output_folder, out_f_name) if max((width_0, height_0)) &lt;= max_px_size: print('writing &#123;&#125; to disk (no change from original)'.format(out_f_path)) img.save(out_f_path) return if width_0 &gt; height_0: wpercent = max_px_size / float(width_0) hsize = int(float(height_0) * float(wpercent)) img = img.resize((max_px_size, hsize), Image.ANTIALIAS) print('writing &#123;&#125; to disk'.format(out_f_path)) img.save(out_f_path) return if width_0 &lt; height_0: hpercent = max_px_size / float(height_0) wsize = int(float(width_0) * float(hpercent)) img = img.resize((wsize, max_px_size), Image.ANTIALIAS) print('writing &#123;&#125; to disk'.format(out_f_path)) img.save(out_f_path) return Today I listened코딩하면서 노래듣다가 찾아들은것들… Franz Schubert: Erlkönig.. https://blog.naver.com/johnleedr/221215711841 Wagner - Das Rheingold - Entry of the Gods Into Valhalla http://extmovie.maxmovie.com/xe/aliencovenant/19623755 Despacito - Luis Fonsi ft.Daddy Yankee (French Version | Version Française by Chloé - COVER )","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"noCUDA","slug":"noCUDA","date":"2019-01-18T20:50:33.000Z","updated":"2019-01-19T00:33:28.651Z","comments":true,"path":"2019/01/19/noCUDA/","link":"","permalink":"http://namwoo.github.io/2019/01/19/noCUDA/","excerpt":"","text":"안된다…이젠 무리다. 더이상 내 컴푸타로는 CUDA..GPU.. 병렬계산 진행이 안된다… 당연히 CPU 연산은 불가능이고 이제 컴터를 바꾸기 전까지는 지금 단계 이상 학습을 진행할 수도 배울 수도 없다… 지금까지 버티고 버텨온 내 콤푸타.때는 바야흐로 2000년.. 무려 20년전.. 조립한 컴퓨터.컴퓨터에 누구보다 빨리 관심이 많았던 나.. 컴 개발자 출신이신 아부지 덕택에 집엔 그 구하기 힘들다는 IBM 컴퓨터와 그 비싸다는 Macintosh가 여럿 있었다. 내가 86년생이니까.. 이때가.. 80년대 후반… 맥은 노트북만 3대, 데탑으로 2대? 3대? Windows PC도 두어대 있었다(1대는 유치원생 어린 내가 속 봐본다고 분해했다가 조립했는데 안켜짐). 그땐 우리집이 PC방이었는데.. ㅎㅎ 추억팔이. 어쨌든 혼자서 PC를 관리하다보니까 PC의 수명은 흔히 3년 주기로 교체한다던데 이건 콤푸터 판매상들의 속셈이고 관리만 잘하면 정말 수년 수십년 나처럼 길게길게 쓸 수 있다. 컴퓨터를 하루웬종일 끼고 켜놓고 며칠연속 켜놓고도 오래오래 유지하는 그 핵심은 하드디스크 관리 메모리 관리 전원부 관리 자세한 건 나중에 자세히 다시 쓸 기회가 있겠지만 핵심은 메모리랑 하드디스크 캐쉬관리면 충분한거 같다. 물론 SSD 몇개더 달고 HDD 더 달고 파워 몇번 바꿔주고 메모리 더 꽂았던게 다… 그리고 최근 모니터 바꾸면서 더 이상 호환 문제로 고이접어 나빌레라.. 메인보드.. CPU 때서 잘 모셔놨다. 그리고 친구가 무려 1080 글픽으로 업글한다고 버리는 CPU랑 메인보드를 주어웠고 이 참에 나도 좋은~~ 글픽좀 써보자 해서 산 1050 글픽카드.. 11만?14만? 주고 산거 같다. CPU : intel i5 4670 Memory : 24Gbytes DDR3 VGA : NVIDA GeForce GTX 1050 2Gbytes CUDA : Compute Capability 6.1 https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1050/ GPU Architecture : Pascal NVIDIA CUDA® Cores : 640 Frame Buffer : 2 2Gbytes GDDR5 Memory Speed : 7 Gbps Boost Clock : 1455 MHz 다른 부속들은 이전에 쓴던 부품 맞으면 최대한 그걸로 썼고 os용 SSD랑 인터넷 캐시관리하면서 프로그램 설치용 SSD에 파일 저장용 HDD.. 기존에 사용하던데로 방식 그대로.. 근데도 안된다…머신러닝, 딥러닝.. 을 병렬연산으로 계산해야하는데 단순한 torchvision datasets 으로 grad 켜놓고 하면 cpu는 단 1 epoch도 돌지 못하고 grad 켜고 cuda로 gpu 계산돌리면 내 클픽 메모리 부족하다고 뜨고..( 이미 모니터에 기타 사용하는거 + 연산이라 실제 사용할 수 있는 메모리는 현저하게 작아진다. ) grad 끄고 cuda로 하면 진행되긴 하는데 여기서부턴 잘 모르겠다. num_worker랑 pin_memory 설정도 gpu 계산을 할 수 없으니 비교해서 알아볼 수도 없다. 그래서 python 에 multiprocessing 해보려는데 자꾸 오류가 난다. 뭐 이건 어떻게든 해결할 수 있을 것 같은데.. 그래도 아무리 cpu가 병렬계산하고 뭐한다 해도 gpu 계산만큼 빠를 수는 없기에…….. 대안이 될 수가 없으니 의욕이 안선다…… 나도 Tesla나 Quadro 같은 QUADRO P6000.. 이 정도? …. 한 글픽카드 하나에 800만원 하겠지? 그냥 멀티프로세싱 파이썬 코딩이나 해보자ㅜㅜ 그래도 안되면… 안된다면… 이젠… 어쩌지?","categories":[],"tags":[{"name":"CUDA","slug":"CUDA","permalink":"http://namwoo.github.io/tags/CUDA/"},{"name":"Torch","slug":"Torch","permalink":"http://namwoo.github.io/tags/Torch/"}]},{"title":"20190118_TIL","slug":"20190118-TIL","date":"2019-01-17T19:48:08.000Z","updated":"2019-01-19T22:45:41.912Z","comments":true,"path":"2019/01/18/20190118-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/18/20190118-TIL/","excerpt":"","text":"궁금증 해결120190117-TMQ q1어제 올린 질문에 빠른 답이 왔다. 질문 링크 20190117-TMQ 중 q1 1234567...# loss = criterion(logits, labels)...running_loss += loss.item()...acuracy = running_loss/len(trainloader)... 코멘트1For your second question, 938 is the number of batches. Since each time we add the loss of a batch into running loss, we average running loss by the number of batches to get the average loss per batch 이 답글을 보고 내가 잘못 이해했던 부분이 있다는걸 깨닳았고 for문은 기존에 데이터셋에 있는 60000데이터포인트에 bath_size가 64니까 총 938번을 반복할꺼고 $64*938=60032$ 들어오는 이미지는 앞서 정한 bath에서 64개의 이미지가 들어오니 출력도 역시 64개, loss도 64개가 된다. running_loss/len(trainloader) 64개의 이미지에서 나온 loss를 전체 반복할 횟수인 938로 나누면 처음은 한 반복에서 나온 loss값이지만 계속해서 반복해서 938번이 끝나면 64개의 이미지씩 938번을 다 끝내게 되고 얻은 모든 이미지에 대한 loss 값의 합으로 나눠줘서 평균, 그러니까 단 한 이미지에서 나오는 loss 값을 구할 수 있다. 궁금증 해결220190117-TMQ q2마찬가지, 어제 올린 질문 두번째꺼. 질문 링크 20190117-TMQ 중 q2 위 코멘트를 보고 자려고 누워서 열심히 짱구를 굴렸는데 발가벗고 뛰어나가는 쏘크라테스처럼 벌떡 일어나서 컴터키고 앉아 적고 있다. 너무 집중을 했는지 누워서 졸았따.ㅡㅡ 앉아서 졸면 꾸벅, 꾸벅 하다 깨는데 바르게 누운 상태에서 생각하다 졸면 허리가 웅크리면서 굽.으려다 펴지고 굽.으려다 펴지는…….. 수면장애..겠…지? 123456789...# log_ps = model(images)test_loss += criterion(log_ps, labels)...# ps = torch.exp(log_ps)top_p, top_class = ps.topk(1, dim=1)equals = top_class == labels.view(*top_class.shape)# accuracy += torch.mean(equals.type(torch.FloatTensor))... 오호라자려다 누워 생각하다 나온 .. 생각의 결론은..? 조금 더 크게 생각해볼때 64개의 이미지씩 처리하니까 64개의 이미지와 그 이미지의 이름이 들어가고 모델을 통해 나온 이미지의 loss도 64개, 그리고 softmax해서 정규화도 64개 top_p, top_class = ps.topk(1, dim=1) 그 이미지들이 무슨 이름인지 각각 확률로 5%, 10%, .. 등등 나열되어 있을 것이고 그 중에 가장 높은 확률로 무슨 이름인거 같다~ 라고 말하는 거 뽑아내서 현재는 파라메터가 1이니까 딱 1개만, 만약에 5면 확률순으로 정렬해서 5개 뽑아내는것이고 equals = top_class == labels.view(*top_class.shape) 실제 라벨과 비교해서 같은게 있으면 1, 없으면 0으로 정리 지금 총 64개의 이미지 중에 같은게, 맞춘게 1, 틀린게 0으로 되어 있는 것을 accuracy += torch.mean(equals.type(torch.FloatTensor)) 평균을 구해서 확률을 구한다!!!!! 유레카!!!! equals.type(torch.FloatTensor) 이건 0또는 1로 되어있는 bit type을 Float 로 바꿔줘서 평균구할 수 있게 하는. 왜 이것들을 이해 못했을까?도미노처럼 앞에 있는 60000, 938, 728, 64 등의 숫자들이 꼬여서 헷갈린듯… 앞이 꼬이니 뒤에서 하나하나 풀려야되는데 특히 64렁 938하고 섞여서 끝 부분 확률 구할때 자꾸 938을 생각하지 않았을까? 938은 그냥 반복 횟수..인데.. 어쨌거나 유레카!!! (잠은 또 못잔건 안비밀) 궁금증 해결3number_worker, pin_memory항상 number_worker를 사용하면 오류가 떴다. 원래는 TMQ 에 올려야 하지만 해결될 거 같은 생각이 들어 미리 써놓고, 여기다 바로 쓸 생각으로 쓰고 있다. ;;","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"MakeMyBlog01","slug":"testtesting","date":"2019-01-17T00:55:21.000Z","updated":"2019-01-17T02:41:25.913Z","comments":true,"path":"2019/01/17/testtesting/","link":"","permalink":"http://namwoo.github.io/2019/01/17/testtesting/","excerpt":"","text":"다시 정리hexo-tag-cloud 넣기hexo-tag-cloud https://www.npmjs.com/package/hexo-tag-cloud?activeTab=readme hexo폴더에 package.json에 [&quot;hexo-tag-cloud&quot;: &quot;2.0.*&quot;] 추가 터미널에서 npm i hexo-tag-cloud 설치 설치된 테마에따라 수정하는 파일명이 다르니 확인 ejs swig 나는 next theme니까 For swig Users jade theme 폴더에 next/layout/_macro/sidebar.swig 찾아서 요거 추가. 123456789101112&#123;% if site.tags.length &gt; 1 %&#125;&lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot; src=&quot;/js/tagcloud.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot; src=&quot;/js/tagcanvas.js&quot;&gt;&lt;/script&gt;&lt;div class=&quot;widget-wrap&quot;&gt; &lt;h3 class=&quot;widget-title&quot;&gt;Tag Cloud&lt;/h3&gt; &lt;div id=&quot;myCanvasContainer&quot; class=&quot;widget tagcloud&quot;&gt; &lt;canvas width=&quot;250&quot; height=&quot;250&quot; id=&quot;resCanvas&quot; style=&quot;width=100%&quot;&gt; &#123;&#123; list_tags() &#125;&#125; &lt;/canvas&gt; &lt;/div&gt;&lt;/div&gt;&#123;% endif %&#125; hexo 폴더에 _config.yml에 이거 추가123456# hexo-tag-cloudtag_cloud: textFont: Trebuchet MS, Helvetica textColour: \\#333 textHeight: 25 outlineColour: \\#E2E1D1 asset folder setting https://hexo.io/docs/asset-folders 테스트 해보기 이게 잘 나오나? 아님 이게 잘 나오나. 그것도 아니면 이게 잘 나오나??? https://www.npmjs.com/package/hexo-directory-category tags, categories 넣기12hexo new page tagshexo new page categories sources/categories/index.md 12345---title: All categoriestype: &quot;categories&quot;date: 2018-01-01 11:06:29--- sources/tags/index.md 12345---title: All tagstype: &quot;tags&quot;date: 2018-01-01 11:06:17--- 다 변경. post 앞단 설정 법. comment 안보이게 하기. https://github.com/iissnan/hexo-theme-next/wiki/%E5%88%9B%E5%BB%BA%E5%88%86%E7%B1%BB%E9%A1%B5%E9%9D%A2 필요없는 곳에선 아래와 같이 설정. 12345title: 分类date: 2014-12-22 12:39:04type: &quot;categories&quot;comments: false--- 앞단123456789---title: 제목도 처음에 터미널에 hexo n 하면서 생성되었음date: 날짜는 알아서 생성됨tags: [Hexo, Theme,Next]categories: [Today, MakingBlog]layout: defaultcover: /img/home-bg.jpg 커버이미지subtitle: 부제목---","categories":[],"tags":[{"name":"Theme","slug":"Theme","permalink":"http://namwoo.github.io/tags/Theme/"},{"name":"Hexo","slug":"Hexo","permalink":"http://namwoo.github.io/tags/Hexo/"},{"name":"Next","slug":"Next","permalink":"http://namwoo.github.io/tags/Next/"}]},{"title":"20190117_TMQ","slug":"20190117-TMQ","date":"2019-01-16T18:03:35.000Z","updated":"2019-01-16T23:51:00.420Z","comments":true,"path":"2019/01/17/20190117-TMQ/","link":"","permalink":"http://namwoo.github.io/2019/01/17/20190117-TMQ/","excerpt":"","text":"아래 질문들은 어제 질문인데 정리하다보니 하루가 넘어가서 새벽 4시 ㅡㅡ q1아래 코드 이해불가1234567...# loss = criterion(logits, labels)...running_loss += loss.item()...acuracy = running_loss/len(trainloader)... running_loss를 왜 append 해주는 걸까? bath_size = 64 였고 input_images.shape = 1*28*28 는 FMNIST dataset, 옷가지 사진에 1ch짜리 이미지들.. len(traindataloder) = 938 FMNIST dataset에 60000개의 데이터포인트에서 bath_size가 64니까 64/60000 = 938 bath_size의 의미는 한번에 불러와서 처리할 이미지의 양. 으로 이해. 그럼 epoch 한번이 돌때 traindataloder에서 64개의 그림이 들어오는 거고 그 과정을 for문으로 938번 하겠다는 거 쭉쭉쭉 모델을 통해서 loss function(얼만큼 틀렸는지 실제 labels과 비교)을 구했고 그걸 exp 해서 이산을 연속으로 바꿔주고 그 값을 정규화해서 확률을 구한다. 그럼 한 epoch 돌았을 때 출력된 loss를 바로 실제 확률로 비교해서 출력하고 다음 epoch 돌았을 때 다시 출력되는 loss를 다시 실제 확률로 비교해서 출력하면 되는거 아닌가? 왜 running_loss = running_loss + loss.item() 이렇게 해서 loss를 쌓지? 그리고 쌓은 loss를 전체 횟수인 len(trainloader) 이걸로 나눠주는 걸까? 왜왜왜왜왜왜왜 loss 를 쌓고 정확도는 또 저렇게 총 반복횟수로 나누는지 전혀 모르겠따. q2아래 코드 역시 이해불가123456789...# log_ps = model(images)test_loss += criterion(log_ps, labels)...# ps = torch.exp(log_ps)top_p, top_class = ps.topk(1, dim=1)equals = top_class == labels.view(*top_class.shape)# accuracy += torch.mean(equals.type(torch.FloatTensor))... 위 q1질문에 이어서.. model을 통해 입력된 images를 criterion까지 거쳐 test_loss를 구하는데 왜 쌓아 또? 그렇다 치고 넘어간 loss를 exp해서 이산으로 바꿔주고 topk 함수써서 가장 높은 확률을 나타내는 1개의 확률 top_p과 실제 top_class을 출력. 위 4번에 나온 top_class를 실제 labels 이미지랑 비교해서 같으면 1, 틀리면 0 만들기. equals.shape = 64*1 일태고 이중 맞은 몇 개가 1일 태지 총 64개중에 맞은게 1개 있으면 확률은 0.15 정도된다. 이게 accuracy… 인데.. 왜? 2번 왜 쌓는지 모르겠고 3-4 로 넘어가는 과정에서 정확히 무슨 확률이 높은걸 뽑아내는지 이해안되고 6번이 왜 accuracy가 되는지 모르겠다. 아아아아아아~~ 모르겠다 누가 알려주세요.. 근데 여기 내 블로그는 검색이 안되는데.. 누가 내 블로그에 검색해서 정리도 안된 홈피에 이걸 찾아 알려줄까.. 게다가 댓글 창도 없는 내 블로그….. 카패 개설하고 스터디 만들어서 직접해보든지 해야하나… 며칠째 끙끙 이걸 해결할 방법이 없네.. q3hexo next thema gitment error다른 블로그에 포스트에 댓글 다는 거 넣고 싶은데 일반적으로 많이 쓰는 facebook은,, 내가 이런 SNS을 전혀 안해서 그냥 넣고 싶지 않았고 gitment는 markdown 으로 이것저것 넣을 수도 있고 너무 확장성도 좋길래 넣으려 했건만 자꾸 오류남. 설정 다 맞추고 oth api 까지 다 넣고 수정하고 enable 로 바꾸고 블라블라 다 해서 블로그에 다는거 까지 잘 됐는데 로긴해서 댓글 달려고 하면 계속 오류남.. repo까지 잘 만들었는데…초기화해주라는데 … 그냥 접속이 안됨… [object ProgressEvent] 개발자가 쭝궈런이라 baidu 돌아다니면서 고치려해봤는데도… https://blog.csdn.net/wardseptember/article/details/82828391 관련 issue 바꿔봐도 안됨… 밤새서 고쳐보다 안되서 버리고 facebook sdk 가입하고 api 받아서 넣음….","categories":[],"tags":[{"name":"TMQ","slug":"TMQ","permalink":"http://namwoo.github.io/tags/TMQ/"}]},{"title":"20190117_TIL","slug":"20190117-TIL","date":"2019-01-16T16:19:19.000Z","updated":"2019-01-17T13:02:38.681Z","comments":true,"path":"2019/01/17/20190117-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/17/20190117-TIL/","excerpt":"","text":"본거 #S.0. 딥러닝 논문리스트로 레딧 1위한 썰, 뒷이야기 2012년 부터 2016년까지 핫했던 논문 리스트. 예전에 봐야지 해놓고 저장해놓거 끄집어내 봄 https://www.youtube.com/watch?v=wZXwBVlmfXA 영상주소 https://www.reddit.com/r/MachineLearning/ 관련글 https://github.com/terryum/awesome-deep-learning-papers#readme 보고 배울 점. 저기 논문들을 내가 읽어보는게 좋은 생각인가? 그냥 영어공부 더 하는게 맞는듯..ㅜㅠ #0.4. SNS로 딥러닝 소식 팔로우 하는 법 (2/2) 최신 딥러닝 소식 팔로우 하는법 싹다 정리해놨는데 실제 행동은 하지 않아서 다시 영상 보고 실행! https://youtu.be/Z1OdPpq9w0o (1/2편) https://www.youtube.com/watch?v=w1oQQmu8NKo (2/2편) https://arxiv.org/ 주로 다른 Science 논문 올리는데 learning 으로 검색 http://www.arxiv-sanity.com/ 핵심, 좀더 정제된 검색, 히스토리 찾을 수 있음 top recent - last week 처럼 설정 조작해서 좋은거 찾을 수 있음 top hype - last year 트윗숫자, 공유 많이 한, 짱짱하냐 확인가능 recommended 내 검색 히스토리 가지고 논문 추천 https://www.reddit.com/r/MachineLearning/ 핵심 hot 은 오늘자 핫한거 top - past week 로 저장해서 확인 https://twitter.com/TerryUm_ML/ 그리고 트위터. 그냥 선수들 팔로우 해서 트윗으로 몰아보고 페이스북 개인 페이지 만들어서 연동 하는게 좋은듯 https://www.facebook.com/terryum.io/ https://github.com/terryum/awesome-deep-learning-papers/ https://www.fb.com/groups/TensorFlowKR/ https://www.fb.com/groups/AIKoreaOpen/ https://www.fb.com/deeplearningtalk/ https://scholar.google.co.kr/ 히든 레이어 여럿일때 이렇게 처리.123456checkpoint = &#123;'input_size': 784, 'output_size': 10, 'hidden_layers': [each.out_features for each in model.hidden_layers], 'state_dict': model.state_dict()&#125;torch.save(checkpoint, 'checkpoint.pth') Batch Normalization in Deep Networks https://www.learnopencv.com/batch-normalization-in-deep-networks/ 읽어봤지만 정리는 안함. ㅜㅜ Dropout Neural Networks https://www.python-course.eu/neural_networks_with_dropout.php Overfitting 오버피팅 줄이기 위해서 Dropout 하는거 개념 다시 정리 아니 도대체 몇번을 또 보고 읽고 이해하는지..ㅡㅡ Fashion-MNIST https://github.com/zalandoresearch/fashion-mnist 데이터셋 확인 멀티프로세싱 관련선구자 https://www.youtube.com/playlist?list=PL5tcWHG-UPH2HrF5M7-IIXK6JSRG0obYo 꼭 다시 가보자 ** Get 10x Speedup in Tensorflow Multi-Task Learning using Python Multiprocessing https://hanxiao.github.io/2017/07/07/Get-10x-Speedup-in-Tensorflow-Multi-Task-Learning-using-Python-Multiprocessing/ 다시 잘 읽고 정리 해보자. 한번쯤 봐볼만하지만 자세한 예와 설명은 없음. How to speed up the data loader https://discuss.pytorch.org/t/how-to-speed-up-the-data-loader/13740 Rookie ask: how to speed up the loading speed in pytorch https://discuss.pytorch.org/t/rookie-ask-how-to-speed-up-the-loading-speed-in-pytorch/4714 https://github.com/python-pillow/Pillow/issues/835 멀티프로세싱 issue https://stackoverflow.com/questions/48822463/how-to-use-pytorch-multiprocessing https://github.com/jhfjhfj1/autokeras/issues/106 https://github.com/pytorch/pytorch/issues/5858 https://pytorch.org/docs/stable/notes/windows.html ** 멀티프로세싱 docs https://pytorch.org/docs/stable/notes/multiprocessing.html https://docs.python.org/3.6/library/multiprocessing.html 나중에 꼭 다시 가서 확인해볼 곳 https://opencv-python.readthedocs.io/en/latest/doc/01.imageStart/imageStart.html hexo thema settinginit setting https://theme-next.org/docs/getting-started/ https://theme-next.iissnan.com/getting-started.html https://imsun.net/posts/gitment-introduction/ 안에 tag 넣고 주석 달고 하는거 연습 https://www.youtube.com/watch?time_continue=1&amp;v=I07XMi7MHd4 https://hexo.io/docs/front-matter.html#Categories-amp-Tags tag 추가 ,https://theme-next.org/docs/theme-settings/#Adding Google Calendar Page&gt; Adding «Categories» Page &lt;https://theme-next.org/docs/theme-settings/#Adding «Categories» Page&gt; 각종 Meta 추가 https://theme-next.org/docs/theme-settings/ https://theme-next.org/docs/third-party-services/comments-and-widgets/#Gitment 관련 참고 http://blog.lattecom.xyz/all-categories/ hexo next thema gitment setting다 해서 블로그에 다는거 까지 잘 됐는데 계속 오류남..[object ProgressEvent] gitment 보안 이거 너무 좋아보이는데 github은 api가 따로 없어서 일반 사용자가 직접 만들고 배포한 저 gitment를 쓰는거라 저 사용자가 oth 권한으로 내 git의 ment repo에 읽고 쓰기 권한이 자동으로 주어짐. (물론 프라이빗은 접근불가) 근데 또 내 yonsei university 학교계정으로 받은 각종 google drive 같은 것도 학교에서 맘대로 보고 쓰고 ㅡㅡ 아예 삭제까지 할 수 있는거 보단 내 퍼블릭 오픈된거 보고 쓸 수 있는거니.. 게다가 추적도 가능하니.. 쓰려했지만.. 자꾸 오류나서 포기.. 그리고 중국… 개발자에 홈피가 중국사이트라 그런건지 자꾸 내 크롬에서 보안경고 뜸.. 아마도 중국홈피에 내부 써드파티에 접속자 분석툴 같은게 google에서 인증 안된.. 거라 그런건가? 그냥 버리고 facebook sdk 로 감.. facebook은 전혀 안하는데 .. 그래서 안쓰려 한건데.. 어쩔 수 없지… 주석넣는거 연습.1Please note that the authorized permission of Gitment will obtain the read and write access to all your public repositories and maybe send github keys to the 3rd-party imsun&apos;s proxy server. If you concern about the security, we strongly deprecated to use gitment. Useful link npm i –save gitment https://github.com/imsun/gitment#get-started https://github.com/settings/applications/new Intersect - a CROS proxy https://github.com/aimingoo/intersect 동영상 넣는 것도 연습 ## blah blah blah blah blah blah blah blah blah ## ## Content (md partial supported) defaultprimarysuccessinfowarningdanger No icon noteNote without icon: note info no-icon 123code block in note tagcode block in note tagcode block in note tag No icon noteNote without icon: note info no-icon 123code block in note tagcode block in note tagcode block in note tag math testSimple inline $a = b + c$. $$\\frac{\\partial u}{\\partial t}= h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\\frac{\\partial^2 u}{\\partial y^2} +\\frac{\\partial^2 u}{\\partial z^2}\\right)$$ This equation $\\cos 2\\theta = \\cos^2 \\theta - \\sin^2 \\theta = 2 \\cos^2 \\theta - 1$ is inline. $$\\begin{aligned} \\dot{x} &amp; = \\sigma(y-x) \\\\ \\dot{y} &amp; = \\rho x - y - xz \\\\ \\dot{z} &amp; = -\\beta z + xy \\end{aligned}$$","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190116_TIL","slug":"20190116-TIL","date":"2019-01-15T17:28:27.000Z","updated":"2019-01-15T23:40:08.096Z","comments":true,"path":"2019/01/16/20190116-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/16/20190116-TIL/","excerpt":"","text":"참고 https://machinelearningmastery.com/transfer-learning-for-deep-learning/ 주피터 노트북 시작폴더 변경법https://code.i-harness.com/ko-kr/q/219f244 어제해야한거 오늘로 미룬거 부터.아래 코맨트 아직 미처리. This is in line with the comments in the saving section. You can recreate the model using model = getattr(models, arch)(pretrained=True) where arch is the architecture string. You would also need to recreate the classifier using nn.Sequential(), and the input, output, and hidden sizes. Your current code is using the previously defined classifier object, which isn’t saved in the checkpoint file, and would break your code if you attempted the load the model from the file without executing all your code above, which defeats the purpose of having a loading function, which should be usable by anyone having only access to the checkpoint file. 모델 선택할 때 나는 이런 느낌으로 다가 했는데 123456789101112if arch=='vgg19_bn': model = models.vgg19_bn(pretrained=True) model_nameprint = 'Default architecture : ' + archelif arch=='vgg13': model = models.vgg13(pretrained=True) model_nameprint = 'Selected architecture : ' + archelse: selected = 'models.'+ arch + '(pretrained=True)' model = selected model_nameprint = 'Selected architecture : ' + arch print(model) raise ValueError('Unexpected network architecture', arch) ## flag !!! 이거 말고 아래로 바꾸라고 함. Using model = getattr(models, arch)(pretrained=True)should load the proper model without the need for an if else statement Some information is missing from the saving code. You should save enough information to be able to reconstruct the model completely. You can save the architecture string, such as “vgg19”, and would need to save additional information such as input, and hidden size so that you can recreate the classifier as well. The goal is to be able to provide the checkpoint file to someone else and run the loading function to recreate your model completely Even though the plot and images are displayed properly, the names of the flowers are incorrect. To be able to get the correct names, you need to first reverse the class_to_to_idx dictionary, and use the topk labels as keys to get the correct class ids. Once you have the class ids, you can then use the class ids strings as keys in the cat_to_name dictionary to retrieve the correct class names. This is why you’re only getting 20-30% of the correct names even though your accuracy is close to 90%. You should be printing the training and validation loss during each epoch of training. Only the training loss is printed here. multiprocessing module 컴이 못따라가줘서 찾아보다보니 알게된 멀티프로세싱. 내 컴으로 cuda 사용시 gtx1050 2gb, 메모리 부족으로 큰건 돌릴 수 없음… 개별로 실행 잘 되는 건 확인 했는데, 실제 내가 사용하는 학습 알고리즘에 적용되는지 넣어보기. 참고. Deep Learning With PyTorch &ndash; Josh Bernhard &ndash; Medium 딥러닝 학습 기술들 &middot; ratsgo’s blog ‘Machine Learning/Theory’ 카테고리의 글 목록 :: UMBUM CS231n Convolutional Neural Networks for Visual Recognition umbum (umbum)","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190115_TIL","slug":"20190115-TIL","date":"2019-01-14T16:45:14.000Z","updated":"2019-01-15T17:46:15.980Z","comments":true,"path":"2019/01/15/20190115-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/15/20190115-TIL/","excerpt":"","text":"어제 끝내거나 아직인거(실은 미룬거) 자기 전 project2 제출 했는데 코멘트 옴. 메일 알람 듣고 자려고 누웠다가 일어나서 확인. 파일제출이 덜 되어 있어 다시 제출. 잠 깨는 바람에 컴터 켰는데. 인터넷 서핑중에 뜨는 창에 정말 맛있게 야식 비빔면 먹는거 보고 배속에서 꼬를르르륽. 새벽3시에 파썰어서 볶음밥….ㅠㅠㅠㅠ ㅠㅠㅠㅠㅠ 오늘 예정(제발 끝낼꺼) 한국어일기 쓰기 시작하자. 영어일기 쓰기 시작하자. 독일어일기 쓰기 시작하자. 중국어일기 쓰기 시작하자. 읭? 1 &gt; 2 &gt; 3 &gt; 4 : 우선순위 최소한 1에서 2까지 만이라도 … 3, 4는 예전에 자주 써버릇했었는데.. 지금은 일단 pass! 오늘 한 일(done!) install WaKatime Chrome, Visual Studio Code, PyCharm 엔 설치 잘 됐는데 Notepad++는 설치 오류. 안돼? 그럼 이젠 안쓸께. checking project2 comment. comment notebook으로 제출한 project는 정확도가 93%가 넘어갔기 때문에 칭찬 하지만 class_to_idx 및 idx_to_class를 사용하여 예측 시 class와 IDs의 이름을 올바르게 지정하라함. All import statements, including the ones provided by default, need to be moved to the first cell. This allows a quick look at all the project’s dependencies, and is a good programming practice. 완료 import를 to the first cell? 읭? 나 모두 그렇게 했는데? 확인해보니 json 불러올때 같이 import json 따로 내놓은게 유일한데 이것 때문인듯.. MNIST data 필기체 인식 코드 줄마다 코멘드 싹 다시 정리. 도저히 빵꾸가 많아서 이해가 안되고 외워졌던 부분 많이 매꿈. (여전히 많은 건 비밀) Module 직접 선언하기 그냥 이런 클래스 형식으로. 1234567891011121314class Network(nn.Module): def __init__(self): super().__init__() self.hidden = nn.Linear(784, 256) self.output = nn.Linear(256, 10) self.sigmoid = nn.Sigmoid() self.softmax = nn.Softmax(dim=1) def forward(self, x): x = self.hidden(x) x = self.sigmoid(x) x = self.output(x) x = self.softmax(x) return x activation function은 꼭 non-linear function 이어야함. 전단계 선형함수를 step이나 sigmoid, ReLu(rectified linear unit), TanH(hyperbolic tangent) 로 바꿔주기 위해. 다시 말하면 Yes or No 또는 1부터 10중에 뭐? 이런 식으로 나타내기 위해 비선형. 이런 의미겠지? 자주 보는 에러.12345678&gt;&gt; torch.mm(features, weights)# matrix multiplication---------------------------------------------------------------------------RuntimeError Traceback (most recent call last)&lt;ipython-input-13-15d592eb5279&gt; in &lt;module&gt;()----&gt; 1 torch.mm(features, weights)RuntimeError: size mismatch, m1: [1 x 5], m2: [1 x 5] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524590658547/work/aten/src/TH/generic/THTensorMath.c:2033 곱셈법칙에 의해 size mismatch, m1: [1 x 5], m2: [1 x 5] 가 발생. 앞 벡터 열과 뒤 벡터 행이 같아야 벡터곱이 가능한데 잘못됐기 떄문에 맞추기 위해 벡터성분 위치 조정. tensor에는 tensor.shape 이 있어서 조정할 수 있음. weights.reshape()weights.resize_()weights.view() weights.reshape(a, b) will return a new tensor with the same data as weights with size (a, b) sometimes, and sometimes a clone, as in it copies the data to another part of memory. weights.resize_(a, b) returns the same tensor with a different shape. However, if the new shape results in fewer elements than the original tensor, some elements will be removed from the tensor (but not from memory). If the new shape results in more elements than the original tensor, new elements will be uninitialized in memory. Here I should note that the underscore at the end of the method denotes that this method is performed in-place. Here is a great forum thread to read more about in-place operations in PyTorch. weights.view(a, b) will return a new tensor with the same data as weights with size (a, b). weights.view(5, 1) 로 바꿔서 해결. 근데 정방향으로 계산할 때랑 역방향으로 계산될 때 자동으로 바뀌게 하려고 view()쓴건주 알았는데 생각해보니까 한쪽이 고정이니 그것도 아니 잖아. 거꾸로 오면 아예 위치를 바꿔줘야하는데? view가 그것도 포함되어 있는 함수인건가? In my experience it’s more convenient to build the model with a log-softmax output using nn.LogSoftmax or F.log_softmax (documentation). Then you can get the actual probabilities by taking the exponential torch.exp(output). With a log-softmax output, you want to use the negative log likelihood loss, nn.NLLLoss (documentation). Exercise: Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and F.log_softmax you’ll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately. loss function 뭐 쓰는지에 따라 model끝단을 맞춰서 바꿔줘야 한다. 또 model 끝단에선 prameter값도 맞춰주어야함. LogSoftmax는 dim값 조정으로 행 대신 열로 계산하게 함. 현재시간 새벽 2시반. 빨리 자야….내일 또 밝은 하루가….!! model.forward(images)model.forward(images) 하는 이유.https://discuss.pytorch.org/t/potential-solution-to-different-forward-for-train-and-inference-ide-support-for-forward-args/33756","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190114_TIL","slug":"20190114-TIL","date":"2019-01-14T03:42:04.000Z","updated":"2019-01-15T06:34:33.713Z","comments":true,"path":"2019/01/14/20190114-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/14/20190114-TIL/","excerpt":"","text":"영어는 언제할꺼임? 일단 오늘 현재까지 한 일 Video program setting done Python Argpare 이것저것 실험해보기. 각각 parameters, argument 비교해보기 https://pymotw.com/3/argparse/ https://docs.python.org/3/library/argparse.html#action github sync 다시 맞추기 100MB 이상되는 파일 껴있을때 해결법 찾기 설정값 조절하라는데 해도 안됨. 100MB 넘는 파일 밖으로 뺴냈는데도 이미 들어간 파일이라 history에 올라가버려니 결국 오류 ignore값 설정해도 이미 그전 history에 먼저 올라가있어 안됨. history revert 하면 컴퓨터에 파일들이 아예 과거로 회귀해버림.. github network에 repo 삭제 -&gt; repo ADD 숨긴파일로 .git history 저장되어 있어서 예전과 같은 상황 발생. github network에 repo 삭제 -&gt; repo Create 아예 그냥 삭제후 다시 만듬. github에 올라있는 이전 파일들 그냥 강제삭제.. 이 방법 밖에는 없는 걸까? Project submission : Udacity Data Scientist Nanodegree Project 2 : Create Your Own Image Classifier 102가지 꽃 종류 판단하기 4일동안 하루~~종일 고치고 실행하고 고치고 실행.. CUDA 없이 그냥 Scikit-learn으로 해볼 때는 수정하고 고치고가 쉬웠고 frontforward, backpropagation 모두 쉽게 예측(?) 해볼 수 있었다. pythorch로 CUDA ON 하고 사용할 때 명령어도 싹 바뀌었고 model parameter 솎아내고 수정하는거, 그리고 argument 설정하는 것들… 고생 좀 했다. vgg19_bn에 linear 1개 더 추가해서 돌렸더니 정확도가 93%까지 올라갔는데 실제 테스트할 때는 도대체가 맞지를 않는다. 너무 올래걸리기도 하고(내 컴 GTX1050 2GB) 내 컴으론 도저히 뭘 할 수가 없어 Udacity 가상머신 GPU 켜놓고, 진행 vgg13으로 linear는 다시 기본으로 input-hidden(512)-output, bath_size=32 로 해서 돌리는데 정확도 67%. 60 넘었으니 일단 pass. 마찬가지.. 이미지 가지고 checking 하는데 자꾸 틀린다…. 왜 그러지? 이것 때문에 이틀 더 걸렸는데… 그래서 그냥 냄…. 그래서 Advisor 에게 멋진 코멘트도 씀.. dear Advisor, please, lead me the right way.. 직역하면 올바른 길로 인도해주세요.. 제바알~~ 123456789101112131415Dear Advisor,1. Development Notebookwhen using Notebook(vgg19_bn) , the accuracy went up 93%, but when check real image, the results were constantly wrong. It&apos;s almost a 20%? 30%? probability.2. Command Line ApplicationLikewise, when check real random image, the results were constantly wrong. I really hope I can fix it. I&apos;ve tried a lot, but i don&apos;t know what to do, where wrong, how fix.please give me a some hint, and lead me the right way.Thank you and Happy new year! 현재시간 오후 10시. 영어는 결국? 59.4 내일 할일 영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어 제발 좀. 영어.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190113_TIL","slug":"20190113-TIL","date":"2019-01-12T16:01:57.000Z","updated":"2019-01-13T16:17:19.376Z","comments":true,"path":"2019/01/13/20190113-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/13/20190113-TIL/","excerpt":"","text":"argparsehttps://docs.python.org/2/library/argparse.html 15.4.3. The add_argument() method 1ArgumentParser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest]) Define how a single command-line argument should be parsed. Each parameter has its own more detailed description below, but in short they are: name or flags - Either a name or a list of option strings, e.g. foo or -f, –foo. action - The basic type of action to be taken when this argument is encountered at the command line. nargs - The number of command-line arguments that should be consumed. const - A constant value required by some action and nargs selections. default - The value produced if the argument is absent from the command line. type - The type to which the command-line argument should be converted. choices - A container of the allowable values for the argument. required - Whether or not the command-line option may be omitted (optionals only). help - A brief description of what the argument does. metavar - A name for the argument in usage messages. dest - The name of the attribute to be added to the object returned by parse_args(). The following sections describe how each of these are used. https://docs.python.org/3/library/argparse.html https://pymotw.com/3/argparse/ TORCH.OPTIMhttps://pytorch.org/docs/stable/optim.html HOW TO ADJUST LEARNING RATEhttps://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate 12345678&gt;&gt;&gt; # Assuming optimizer has two groups.&gt;&gt;&gt; lambda1 = lambda epoch: epoch // 30&gt;&gt;&gt; lambda2 = lambda epoch: 0.95 ** epoch&gt;&gt;&gt; scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2])&gt;&gt;&gt; for epoch in range(100):&gt;&gt;&gt; scheduler.step()&gt;&gt;&gt; train(...)&gt;&gt;&gt; validate(...) 12345678910&gt;&gt;&gt; # Assuming optimizer uses lr = 0.05 for all groups&gt;&gt;&gt; # lr = 0.05 if epoch &lt; 30&gt;&gt;&gt; # lr = 0.005 if 30 &lt;= epoch &lt; 60&gt;&gt;&gt; # lr = 0.0005 if 60 &lt;= epoch &lt; 90&gt;&gt;&gt; # ...&gt;&gt;&gt; scheduler = StepLR(optimizer, step_size=30, gamma=0.1)&gt;&gt;&gt; for epoch in range(100):&gt;&gt;&gt; scheduler.step()&gt;&gt;&gt; train(...)&gt;&gt;&gt; validate(...) 설치 http://bob3rdnewbie.tistory.com/313https://pytorch.org/get-started/locally/ [Window Title]Python [Main Instruction]Python의 작동이 중지되었습니다. [Content]문제에 대한 해결 방법을 확인하는 중입니다. [취소] https://tensorflow.blog/2018/04/25/pytorch-0-4-0-release/https://tensorflow.blog/2018/04/25/pytorch-0-4-0-release/ https://github.com/tensorflow/tensorflow/issues/22794conda create –name tf-gpuconda install -c aaronzs tensorflow-gpuconda install -c anaconda cudatoolkitconda install -c anaconda cudnnconda install keras-gpu https://github.com/pytorch/pytorch/issues/4518from torch._C import * (ImportError: DLL load failed: The specified module could not be found. https://pytorch.org/docs/stable/torch.html#torch.topk","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190112_TIL","slug":"20190112-TIL","date":"2019-01-12T06:51:29.000Z","updated":"2019-01-12T08:00:04.044Z","comments":true,"path":"2019/01/12/20190112-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/12/20190112-TIL/","excerpt":"","text":"TIL. 올라라 정확도야.새벽 6시까지 진행중인거 보다 잠듬. VGG19_BN 모델 batch size 조정12batch size=8num_workers=2 엄청~ 나게 오래걸림. 정확도도 너무 낮음.. 12batch size=32num_workers=0 더 빨라졌는데 정확도가 70프로대가 한계.. 12batch size=64num_workers=0 다시 계산중인데 확실히 빠르고 현재 93프로까지 정확도가 상승","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"TILStart","slug":"TILStart","date":"2019-01-11T06:15:30.000Z","updated":"2019-01-17T01:07:47.208Z","comments":true,"path":"2019/01/11/TILStart/","link":"","permalink":"http://namwoo.github.io/2019/01/11/TILStart/","excerpt":"","text":"intro어릴 때부터 끄적끄적 적어놓는걸 좋아했다. 이곳저곳 교과서 귓퉁이부터 포스트잇, 종이쪼가리 어디든 보이는 곳에다가. 스마트폰을 사용하면서 자연스럽게 구글캘린더와 에버노트, 몇가지 아기자기한 어플들을 사용해서 수년을 적었는데 에버노트 유료라서 안쓰게 되고 어플들은 휴대폰 초기화나 교체 중에 백업파일 오류로 몇년짜리 자료가 날라가면서 의욕도 사라지고 고정 활동들을 안하게 되면서 매번 하던걸 안해도 되어버리니 자연스럽게 최근에는 그 빼곡히 채우던 즐거움이 사라졌다. 몇개의 컴퓨터와 휴대기기들을 쓰다보니까 연동문제도 그렇고 유료문제도 걸려있어서 더욱 … 어쨌거나 저쨌거나 다시 정리하기로 마음 먹었으니 일기로 또는 개발일지로 또는 반성일지로 활용하면서 꾸준히 쌓아보자. 페이스북, 인스타그램, 블로그를 전혀 안해오고 하는 법도 모르지만… 이것 만큼은 꼭 꾸준히 나를 위해서. 내 미래를 위해서. 해보자. 뭔가를 쓸 때 나름의 성취욕? 성과욕? 이 있으면 좋을 것 같아 지금 github에 contributions 처럼 2014년도에 있는 단 1건의 나의 contribution… 이렇게 시각화, 시각적, 비주얼적으로다가 그래프와 도표 등을 활용해서 약간 PM처럼.. agile? waterfall? 뭐랄까 그런 그림적인 느낌적인 느낌으로다가 작성을 해보려한다. 그리고 모든 것들을 당일 저녁 12시 이전에 꼭 push! goal OneNote 컴퓨터간 휴대기기간 싱크 맞추기 계정 통합, 정리, 이동 OneNote와 Github sync 확인 Google Google Calendar sync Google Timeline sync Evernote에 있는 과거정리내용 옮길건 옮기기 예전 어플들 backup 내용 확인, 정리 시각화를 어떻게 하면 좋을지 찾아보기 TILPEP 8Python Enhancement Proposalshttps://www.python.org/dev/peps/#introduction PEP 8Style Guide for Python Codehttps://www.python.org/dev/peps/pep-0008/ 오늘 찾은 위의 정보나 내용을 어떻게 넣을지 확인 diary life info 관심?관심, 흥미 잠깐 눈이 갔었던.. 것들은 영어표현을 어떻게 해야하나..? 거기서 조금 더 관심이 가 깨작 거리는 것들은 또 어떻게 표현하는게 맞으려나? done일단 형태만 갖추기. 주소줄이기https://goo.gl/ 듣고 있는, 들으려는, 들었던 강의 정리(Google Docs)https://goo.gl/c3T37m 읽고 있는, 읽으려는, 읽었던 책 정리(Goole Docs)https://goo.gl/rJcKLv 오늘의 TILBatch Size in Deep Learning 참고 https://blog.naver.com/wideeyed/221425994244 https://blog.lunit.io/2018/08/03/batch-size-in-deep-learning/ 몇 가지 parameter를 조정하면서 Accuracy 향상을 노려보고 있는데 아직 초심자 입장에서 각각의 배포되는 Docs를 보면 너무 다양하고 많은 parameter가 있어서 이번에 몇가지를 건드려봤다. 물론 실제 산업에서 어떻게 이용, 응용, 사용되는지를 모르고 있으니 이게 맞는지도 모르겠고 그렇다고 parameter 조정 논문들을 다 뒤져볼 수도(당장) 없으니 일단 하나씩… 공부할 때 batch size 라는 개념은 나는 bit로 생각했다. 쉽게 컴퓨터가 단일, 1개의 라인으로 처리하는게 아니라 병렬로 64개의 줄을 만들어 처리한다고 이해했다. 높을 수록 속도가 빠르고 빠른만큼 놓치는 부분들로 인해 오류값이 올라간다. 정도? 그래서 알아보기 시작했다. Recall: Stochastic Gradient Descent (SGD)loss function를 줄이기 위해 Gradient Descent로 backpropagate와 frontforward를 반복하는건 알고 있다. 그리고 계산량이 많아질 수 있어서 전체 데이터가 아닌 random 데이터로 추려내서 계산하고 있는 방법도 알고 있었다. 또 최소가 되는 점을 찾다가 local mininum이 발생할 수 있어서 momentum, 가중치로 예전값일 수록 $\\beta$ 값을 상대적으로 작게, 최근값은 크게 주는 것도 알고 있다. 그럼 도대체 batch size란? Stochastic Gradient Descent는 전체 데이터에 대해 엄청난 계산량을 줄이고자 한 반복횟수에 하나의 examle만 사용하는 방법이다. 이 경우 추정된 Gradient 값이 너무 noise 해진다는 단점이 있어 이 방법을 보완하기 위해 매 횟수마다 적당한 크기의 mini-batch에 대한 Gradient를 사용하는 Mini-Batch Stochastic Gradient Descent (SGD)이며 딥러닝에서 가장 일반적으로 사용되는 기법 이라 한다고 한다. 이때 나오는 batch size가 클수록 Gradient가 정확해지지만 한 반복에 계산량이 늘어나고 …. ?? 모르겠다. 어쨌든 batch size가 높으면 빠르다. batch size가 낮으면 속도가 느리다. (high variance) 모델마다 상황에 맞는, 가장 높은 정확도를 나타내는 batch size가 있다.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"},{"name":"Diary","slug":"Diary","permalink":"http://namwoo.github.io/tags/Diary/"}]},{"title":"whatastupidday","slug":"whatastupidday","date":"2018-12-30T07:34:28.000Z","updated":"2019-01-17T03:17:42.415Z","comments":true,"path":"2018/12/30/whatastupidday/","link":"","permalink":"http://namwoo.github.io/2018/12/30/whatastupidday/","excerpt":"","text":"두 달 전부터 써오고 준비했던, 누구보다 미리미리 준비하고 써왔던 원서를 제출 못했다30분 전에 제출하려고 보니 pdf 를 올리는 게 아니고 그걸 또 나눠서 올려야 하는 거였고 파일명을 한국어를 빼고 하길 권고 하길래 혹시 몰라 또 파일명을 일일이 바꿔주었고 그렇게 들어갔더니 결제.. 결제과정에 설치하고 가상계좌를 받니 뭐하니 넘어가고 결제는 휴대폰 계좌이체로 진행보안카드 입력 중 2회오류.ㅡㅡ 분명 똑같이 눌렀는데도 오류..3번째 오류면 대참사이니 마지막 기회라고 천천히 눌러서 버튼을 누른 순간 마감시간 오후 5시1분에 1초가 넘어가버려 계좌이체 실패….. 나 같은 바보가 또 있을까?전화했더니 나 같은 사람이 또 많았나 보다. 묻고 따지고 듣지도 않고 무조건 안된단다. ‘아니 혹시 시스템 상에 오류가 있을 수도 있으니 확인해주시면 안될까요?’ 내가 하는 말이 끝나기도 전에 안된단다. 나 스스로 본인에게 화나고 이런 나에게 대처하는 직원에게 화나고 하지만 멍청한 내 자신에 더 어의없고.. 이제 1년을 기다려야하네? ………. 안녕.. 너랑은 인연이 없나보다.","categories":[],"tags":[]},{"title":"scholarship","slug":"scholarship","date":"2018-12-24T06:01:47.000Z","updated":"2018-12-24T06:01:47.482Z","comments":true,"path":"2018/12/24/scholarship/","link":"","permalink":"http://namwoo.github.io/2018/12/24/scholarship/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"car_accident_almost","slug":"car-accident-almost","date":"2018-12-24T01:06:06.000Z","updated":"2018-12-24T06:08:16.082Z","comments":true,"path":"2018/12/24/car-accident-almost/","link":"","permalink":"http://namwoo.github.io/2018/12/24/car-accident-almost/","excerpt":"","text":"끌어오르는 분노를 억누르며 집으로 들어와 랩탑으로 네비영상을 뽑아 컴으로 다시 확인하니 다시 솓구친다. 분노가. 월요일이면 거의 하루에 운전만 많게는 6시간. 최소 3시간반? 하는 날이다. 오늘도 어김없이 70km 떨어진 곳에 동생을 내려주고 다시 돌려 집으로 돌아오는 길에 구형 똥빠리색 마티즈가 자기 차로는 고속도로로 빠지는 곳이니 급차선 변경으로 내 바로 앞으로 끼어든다. 깜빡이도 없이… 저런 분 많지. 그래.. 내가 조심해야지.. 하면서 고속도로에서 빠지는 방향으로 미리미리 들어와서 미리미리 속도 줄이고(바닥에 빨간라인 따라) 유유히 나가는데 옆차선에서 또 깜빡이도 없이.. 끼어들지 말라고 하옇고 굵게 거북이 등껍질처럼 V표 좍좍 그려논 곳을 뚫고 내 앞을 가로막는다. 근데 영상을 다시 보면서 느끼는 거지만 확실히 내가 직접 운전할 때 느꼈던 그 긴장감? 사고나기 직전 그 쫄깃한 상황? 그건 잘 느껴지지 않지만 실제론 엄청 위험했고 훨씬 가까웠으며 엄청 놀랐던 그 상황… 놀래서 빵도 못하고 …미안한지 뒤에서 깜빡이 켜주던데.. 그럼 뭐해..그렇게 해서 사고나면.. 내 과실도 전방부주의 땡겨 갈꺼면서..어휴..","categories":[],"tags":[]},{"title":"algolia","slug":"algolia","date":"2018-12-19T05:46:41.000Z","updated":"2018-12-19T07:02:23.603Z","comments":true,"path":"2018/12/19/algolia/","link":"","permalink":"http://namwoo.github.io/2018/12/19/algolia/","excerpt":"","text":"정신없는 몇 주. 강의도 끝내야 했고 과제도 시험도 도와줘야 했고 또 오래걸리고 힘들었던 프로젝트를 진행하면서 수업시간에 배웠던 내용들도 복습해야 했고 그걸 가지고 kaggle에 competition도 해봤다. (17위!! 참가자가 별로 없다는게 비밀) 그리고 나서 뻐근한 어께도 풀어줄겸 쉬엄쉬엄(?) 블로그를 떠돌다가 algolia라는 검색엔진? 검색분석엔진? 을 찾고 내 블로그에도 적용해보기 위해 빨래 2번 돌릴 시간 동안(드럼세탁기 삶음기능 2번) 이리저리 시도해봤다. Register at Algolia 가입 그리고 알고리아가 뭔지 확인 https://www.algolia.com/첫 가입 후 14일 후면 FREE모드로 넘어가서 한달에 up to 10k records and 100k operations per month.확인은 빌링탭 가입 후 dashboard 탭에 보면 왼쪽 사이드탭에 Indices 눌러서index 버튼 왼쪽에 이름 눌러서Create index이름은 원하는데로. 나는 원래 깃헙 블로그파일명인 myBlog 또 다시 왼쪽 사이드탭에API Keys를 눌러보면 Your API Keys 탭에 있는 정보 Application ID = 블라블라 Search-Only API Key = 블라블라 이 두 개를 잘 기억 그리고 github 블로그에 테마가 설치되어 있는 원래 기본적으로 블로그에 사용하던 폴더로 이동해서 123npm install --save hexo-algolianpm i hexo-generator-json-content --savenpm i --save hexo-wordcount git 설정 _config.yml 추가 12345algolia: applicationID: 기억해놓은 Application ID 블라블라 입력 apiKey: 역시 기억해놓은 Search-Only API Key 블라블라 입력 indexName: 아까 Create index로 만든 이름 입력 chunkSize: 5000 그리고 테마 설정 _config.ymlalgolia_search 값을 true로 123456789# Algolia Searchalgolia_search: enable: true hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: \"We didn't find any results for the search: $&#123;query&#125;\" hits_stats: \"$&#123;hits&#125; results found in $&#123;time&#125; ms\" 그리고 윈도우os 일 경우실행-cmd에서1set HEXO_ALGOLIA_INDEXING_KEY=Search-Only API key # Use Windows command line 맥이라면1$ export HEXO_ALGOLIA_INDEXING_KEY=Search-Only API key # Use Git Bash 환경변수값 설정하는건데 직접 윈도우 성능에 고급, 환경변수 들어가서 추가했더니 안됨. 위 쓴데로 하는게 더 쉬움. 다 되면12$ hexo clean $ hexo algolia 그리고 잘 적용됐는지 12$ hexo generator$ hexo deploy 급 생각난 현주누나의 명언 출처https://github.com/algoliahttps://www.npmjs.com/package/hexo-algolia#api-keyhttps://github.com/theme-next/hexo-theme-next/blob/master/docs/ALGOLIA-SEARCH.mdhttps://zouzeir.xyz/2017/01/16/Hexo%E9%9B%86%E6%88%90Algolia%E6%90%9C%E7%B4%A2%E6%8F%92%E4%BB%B6/https://elfinlas.github.io/2018/06/07/hexo-usea-lgolia/","categories":[],"tags":[]},{"title":"tree","slug":"tree","date":"2018-12-10T23:27:27.000Z","updated":"2019-01-17T03:17:31.006Z","comments":true,"path":"2018/12/11/tree/","link":"","permalink":"http://namwoo.github.io/2018/12/11/tree/","excerpt":"","text":"올해도 이뻐보이네. 설명회가 있어서 가뜩이나 복잡해진 금요일 저녁 신촌이기에 미리미리 가있으려 했지만.. 역시 꼼지락 거리다 늦장 부리기도 했고..부랴부랴 뛰어서 시간 맞춰서 간신히 도착했으나…. 경영관에서는 대우관으로요.대우관에서는 경영관으로요.잉? 대우관 별관 가봤더니 대우관으로요.읭? 경영관 같은데요? 인터넷 다른 모든 글에는 경영관이었는데 공지 설명글 마지막에 대우관. 결과적으로 대우관은 나중에 저기서 강의하겠다는 내용이었고또 오늘이 아닌 다음주에 진행하는 거였기 때문에 아무도 없었던 ….. 올해가 끝나가기 전에도 바보짓 하는 바보 같은 나의 행동에 감탄하며집에가려고 경영관 중앙 엘레베이터를 탔는데 (통유리라 사방이 잘보임, 그리고 나 혼자)바로 밑에 층에서 직원이라기엔 어리고 대학원생 처럼 보이는 여자분 한 분이 타자마자트름을..꺼억.. 일반적인 소리 큰 트름이 아닌, 속에서 기 모아 올라오는 소리 적고 내용 가득 담은 그 트름을. ㅡㅡ 가뜩이나 바보 같은 짓 한 나 더 정신차리라고 맡으라고 쏟아내신 거겠지.. 암 난 혼나야지.. 그렇게 나오는데 트리에 불이 환한거 보고 나는 바보 같지만 저건 이뻐서 찰칵.","categories":[],"tags":[{"name":"Yonsei University","slug":"Yonsei-University","permalink":"http://namwoo.github.io/tags/Yonsei-University/"}]},{"title":"things","slug":"things","date":"2018-12-06T01:11:35.000Z","updated":"2018-12-06T01:13:23.762Z","comments":true,"path":"2018/12/06/things/","link":"","permalink":"http://namwoo.github.io/2018/12/06/things/","excerpt":"","text":"해야 할 것들이 너무 많어..하고 싶은 것들도 너무 많어..시간은 너무 빨리가고 있고..나이는 한 살씩 늘어나는데머리 속은 채워지지 못하는 이 느낌","categories":[],"tags":[]},{"title":"대학원 알아보기(1)","slug":"MD1","date":"2018-12-05T00:43:33.000Z","updated":"2018-12-05T00:46:11.156Z","comments":true,"path":"2018/12/05/MD1/","link":"","permalink":"http://namwoo.github.io/2018/12/05/MD1/","excerpt":"","text":"첫 깃헙블로그 테스팅 3번째 글.깃헙에서 그리고 내 로컬에서 잘 올리고 받고 확인도 되었는데한글이 깨지길래 이것저것 업뎃하니까 잘 되길래 봤더니 또 깨지네..지금 이 글은 안깨지고 있으려나..? Master Degree, Graduate School 을 알아보면서 정리도 할겸거기다가 github 공부도 할겸 알아가보자 why do I need a degree?각종 MOOC 를 들으면서 nanodegree도 따고 specialization도 계속 따고 있고이리저리 더 공부해보다보니 배움이 더 고파진다.온라인엔 전세계에 내노라 하는 석학들의 무료오픈소스 수업들이 널리고 널렸다.amr chiar scholar 인 나에겐 너무너무 좋은 분들.. 온라인의 장점을 최대한 챙기면서오프라인의 강점을 살리기 위해선 대학원은 필수인거 같아 알아보게 되었다. conditional statement: tuition : 학비가 감당할 정도여야 할 것. 그래봤자 어차피 학자금 대출. 통학, 교통, 숙식. 가진거 없이 학자금 대출로 공부하는거니 최대한 아낄 수 있어야 한다는 점. 해외든 어디든 상관없이 배울 수 있고 스스로 성장할 수 있다면 최우선으로! keywords: Data analyst, Data Science, Data Engineering 이럴꺼면 산업대학원, 일하면서 석사 따는게 더 좋아보이기도 했는데..후자는 확실한 길이 보이지 않았고 모자란 내 짱구로 생각해본 결과…경제 상황 상, 취업 구직난 상으로 볼 때 신입이 성장하기 힘들어보일거 같다는 뇌피셜.로 패쓰. in China중국.. 내수가 짱짱한 나라니 중국어 잘하면 한국오지말고 세계 어디에서든지 생활하면 참 좋을거라는건 누가 말하주지 않아도 중국에서 고등학교를 다녀본 조기유학을 통해 느껴보았고, 중국에서 그 친구들이 지금까지 살고 있는 20년, 아니지 부모님부터 자녀까지 중국에서 거주하고 있는 친구들이 주변에 많이 있다보니 중국은 항상 눈독드리는 나라. if (in China)also if (Chinese and English languages) than ok. 중국에선 중국어만 해서는 안된다. 학위만 따올거라면 모르겠는데 취업까지 넘어가려면 돈 많고 능력 뛰어난 American Chinese 같은 친구들이 너무너무너무너무너무 많다. 북대, 칭화대 애들….. 중국 수십억명중에서 뽑히고 뽑히고 뽑힌 애들을 따라갈 수는 없다.. 언어를 잘해야 어떻게 말이라도 붙여보고 배울텐데 언어도 못하면서 공부하겠다면.. 언어배우다 시간만 낭비할께 뻔한 상황.. 이건 미국, 독일, 일본 어디든 마찬가지.. 거기다 조선족.. 요즘 조선족분들… 예전엔 중국에서 한국어가 들리면 조선족과 한국인을 구별하는건 너무너무 쉬웠다. 일본인, 한국인, 중국인 구별하는 것도 너무 쉬웠고.근데 요즘은 옷, 행동, 말습관 모두 너무 비스므리해지고 체형도 많이 또 바뀌고..아직 외모적으로는 차이가 나는게 보이지만한국에 있는, 전문직종에 일하는 조선족들은 와…. 한국인보다 한국말도 잘하고 죄다 엘리트.. 중국에서 중국어 가르쳐주시던 조선족 과외선생님이 계셨는데그분은 중국어, 한국어 에다가 일본어, 영어까지……어차피 중국어랑 한국어는 기본이고 교육과정상 영어는 또 당연히 할 수 있고..취미로 일본어 하나 더 하면 이미….4개 국어..이쪽 언어들은 유럽애들처럼 언어학적으로 비스므리해서 독일프랑스 애들 모이면 대충 50% 이해하고 넘어가는 것도 아닌데 이미 4개국어..출발선부터 다른.. 분들과 경쟁하려면 나도 나만의 경쟁력을 길러야하기에.. 한국 돌아오면 비벼볼 수는 있다.워낙 한국에 적을두고 해외를 갔다오면 한국에서 그래도 어느 기준으로 공부를 했구나라는게 눈치껏 보인다.돈으로 해외대학가서 언어만 잘해오는 해외파들이 넘쳐나기에 그 사람들보다 경쟁력있으려면 언어는 못할지라도 실력으로 밀어야…. (실력만 가지고 안되는게 세상이던데..) 다시 돌아와서.beijing 아니면 shanghai, hongkong 쪽인데 Tsinghua University 쪽은 이거 3개 Tsinghua-UC Berkeley Shenzhen InstituteData Science and Information Technology (M)(ED) Global Innovation eXchange Institute,Tsinghua UniversityData Science and Information Technology (M) Graduate School at Shenzhen，Tsinghua UniversityData Science and Information Technology (M) 홍콩 쪽, 상해 쪽은 뒤에 이어서… 대학원 알아보기(2) 어디든 들어가서 열심히 공부, 최선을 다해 노력 만 가지고는 복잡한 세상 편하게 살 수 없어졌고어딜가나 해외는 수 많은 네이티브들과 경쟁해야 할텐데 영어랑 로컬, 그리고 추가외국어까지.. 그리고 당연히 실력까지 있어야 하니 전략적 잘 접근해야 요즘 같은 때에 살아남고 먼 훗날을 도모할 수 있으리니..","categories":[],"tags":[{"name":"master degree","slug":"master-degree","permalink":"http://namwoo.github.io/tags/master-degree/"}]},{"title":"post","slug":"post","date":"2018-12-04T16:06:06.000Z","updated":"2018-12-04T16:08:53.231Z","comments":true,"path":"2018/12/05/post/","link":"","permalink":"http://namwoo.github.io/2018/12/05/post/","excerpt":"","text":"�� ������ Ȯ��Ȯ��","categories":[],"tags":[]},{"title":"first-post","slug":"hello-world","date":"2018-12-04T10:24:17.964Z","updated":"2018-12-05T00:47:19.459Z","comments":true,"path":"2018/12/04/hello-world/","link":"","permalink":"http://namwoo.github.io/2018/12/04/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.�׽�Ʈ�׽�Ʈ�ѱ��� �Ƚ��� Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing�׽�Ʈ�׽�Ʈ Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}