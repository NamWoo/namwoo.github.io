{"meta":{"title":"my Blog of Absolute and Subjective Knowledge","subtitle":"지극히 개인적이고 주관적이고 상대적이며 절대적인 나만의 블로그","description":"data scientist, biomedical Engineering","author":"Namwoo Kim","url":"http://namwoo.github.io"},"pages":[{"title":"tags","date":"2019-01-16T20:35:38.000Z","updated":"2019-01-16T23:09:34.882Z","comments":true,"path":"tags/index.html","permalink":"http://namwoo.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-01-16T20:35:57.000Z","updated":"2019-01-16T20:35:57.137Z","comments":true,"path":"categories/index.html","permalink":"http://namwoo.github.io/categories/index.html","excerpt":"","text":""},{"title":"schedule","date":"2019-01-16T20:36:08.000Z","updated":"2019-01-16T20:36:08.705Z","comments":true,"path":"schedule/index.html","permalink":"http://namwoo.github.io/schedule/index.html","excerpt":"","text":""}],"posts":[{"title":"20190117_TMQ","slug":"20190117-TMQ","date":"2019-01-16T18:03:35.000Z","updated":"2019-01-16T23:51:00.420Z","comments":true,"path":"2019/01/17/20190117-TMQ/","link":"","permalink":"http://namwoo.github.io/2019/01/17/20190117-TMQ/","excerpt":"","text":"아래 질문들은 어제 질문인데 정리하다보니 하루가 넘어가서 새벽 4시 ㅡㅡ q1아래 코드 이해불가1234567...# loss = criterion(logits, labels)...running_loss += loss.item()...acuracy = running_loss/len(trainloader)... running_loss를 왜 append 해주는 걸까? bath_size = 64 였고 input_images.shape = 1*28*28 는 FMNIST dataset, 옷가지 사진에 1ch짜리 이미지들.. len(traindataloder) = 938 FMNIST dataset에 60000개의 데이터포인트에서 bath_size가 64니까 64/60000 = 938 bath_size의 의미는 한번에 불러와서 처리할 이미지의 양. 으로 이해. 그럼 epoch 한번이 돌때 traindataloder에서 64개의 그림이 들어오는 거고 그 과정을 for문으로 938번 하겠다는 거 쭉쭉쭉 모델을 통해서 loss function(얼만큼 틀렸는지 실제 labels과 비교)을 구했고 그걸 exp 해서 이산을 연속으로 바꿔주고 그 값을 정규화해서 확률을 구한다. 그럼 한 epoch 돌았을 때 출력된 loss를 바로 실제 확률로 비교해서 출력하고 다음 epoch 돌았을 때 다시 출력되는 loss를 다시 실제 확률로 비교해서 출력하면 되는거 아닌가? 왜 running_loss = running_loss + loss.item() 이렇게 해서 loss를 쌓지? 그리고 쌓은 loss를 전체 횟수인 len(trainloader) 이걸로 나눠주는 걸까? 왜왜왜왜왜왜왜 loss 를 쌓고 정확도는 또 저렇게 총 반복횟수로 나누는지 전혀 모르겠따. q2아래 코드 역시 이해불가123456789...# log_ps = model(images)test_loss += criterion(log_ps, labels)...# ps = torch.exp(log_ps)top_p, top_class = ps.topk(1, dim=1)equals = top_class == labels.view(*top_class.shape)# accuracy += torch.mean(equals.type(torch.FloatTensor))... 위 q1질문에 이어서.. model을 통해 입력된 images를 criterion까지 거쳐 test_loss를 구하는데 왜 쌓아 또? 그렇다 치고 넘어간 loss를 exp해서 이산으로 바꿔주고 topk 함수써서 가장 높은 확률을 나타내는 1개의 확률 top_p과 실제 top_class을 출력. 위 4번에 나온 top_class를 실제 labels 이미지랑 비교해서 같으면 1, 틀리면 0 만들기. equals.shape = 64*1 일태고 이중 맞은 몇 개가 1일 태지 총 64개중에 맞은게 1개 있으면 확률은 0.15 정도된다. 이게 accuracy… 인데.. 왜? 2번 왜 쌓는지 모르겠고 3-4 로 넘어가는 과정에서 정확히 무슨 확률이 높은걸 뽑아내는지 이해안되고 6번이 왜 accuracy가 되는지 모르겠다. 아아아아아아~~ 모르겠다 누가 알려주세요.. 근데 여기 내 블로그는 검색이 안되는데.. 누가 내 블로그에 검색해서 정리도 안된 홈피에 이걸 찾아 알려줄까.. 게다가 댓글 창도 없는 내 블로그….. 카패 개설하고 스터디 만들어서 직접해보든지 해야하나… 며칠째 끙끙 이걸 해결할 방법이 없네.. q3hexo next thema gitment error다른 블로그에 포스트에 댓글 다는 거 넣고 싶은데 일반적으로 많이 쓰는 facebook은,, 내가 이런 SNS을 전혀 안해서 그냥 넣고 싶지 않았고 gitment는 markdown 으로 이것저것 넣을 수도 있고 너무 확장성도 좋길래 넣으려 했건만 자꾸 오류남. 설정 다 맞추고 oth api 까지 다 넣고 수정하고 enable 로 바꾸고 블라블라 다 해서 블로그에 다는거 까지 잘 됐는데 로긴해서 댓글 달려고 하면 계속 오류남.. repo까지 잘 만들었는데…초기화해주라는데 … 그냥 접속이 안됨… [object ProgressEvent] 개발자가 쭝궈런이라 baidu 돌아다니면서 고치려해봤는데도… https://blog.csdn.net/wardseptember/article/details/82828391 관련 issue 바꿔봐도 안됨… 밤새서 고쳐보다 안되서 버리고 facebook sdk 가입하고 api 받아서 넣음….","categories":[],"tags":[{"name":"TMQ","slug":"TMQ","permalink":"http://namwoo.github.io/tags/TMQ/"}]},{"title":"20190117_TIL","slug":"20190117-TIL","date":"2019-01-16T16:19:19.000Z","updated":"2019-01-17T00:42:01.875Z","comments":true,"path":"2019/01/17/20190117-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/17/20190117-TIL/","excerpt":"","text":"히든 레이어 여럿일때 이렇게 처리.123456checkpoint = &#123;'input_size': 784, 'output_size': 10, 'hidden_layers': [each.out_features for each in model.hidden_layers], 'state_dict': model.state_dict()&#125;torch.save(checkpoint, 'checkpoint.pth') Batch Normalization in Deep Networks https://www.learnopencv.com/batch-normalization-in-deep-networks/ 읽어봤지만 정리는 안함. ㅜㅜ Dropout Neural Networks https://www.python-course.eu/neural_networks_with_dropout.php Overfitting 오버피팅 줄이기 위해서 Dropout 하는거 개념 다시 정리 아니 도대체 몇번을 또 보고 읽고 이해하는지..ㅡㅡ Fashion-MNIST https://github.com/zalandoresearch/fashion-mnist 데이터셋 확인 멀티프로세싱 관련선구자 https://www.youtube.com/playlist?list=PL5tcWHG-UPH2HrF5M7-IIXK6JSRG0obYo 꼭 다시 가보자 ** Get 10x Speedup in Tensorflow Multi-Task Learning using Python Multiprocessing https://hanxiao.github.io/2017/07/07/Get-10x-Speedup-in-Tensorflow-Multi-Task-Learning-using-Python-Multiprocessing/ 다시 잘 읽고 정리 해보자. 한번쯤 봐볼만하지만 자세한 예와 설명은 없음. How to speed up the data loader https://discuss.pytorch.org/t/how-to-speed-up-the-data-loader/13740 Rookie ask: how to speed up the loading speed in pytorch https://discuss.pytorch.org/t/rookie-ask-how-to-speed-up-the-loading-speed-in-pytorch/4714 https://github.com/python-pillow/Pillow/issues/835 멀티프로세싱 issue https://stackoverflow.com/questions/48822463/how-to-use-pytorch-multiprocessing https://github.com/jhfjhfj1/autokeras/issues/106 https://github.com/pytorch/pytorch/issues/5858 https://pytorch.org/docs/stable/notes/windows.html ** 멀티프로세싱 docs https://pytorch.org/docs/stable/notes/multiprocessing.html https://docs.python.org/3.6/library/multiprocessing.html 나중에 꼭 다시 가서 확인해볼 곳 https://opencv-python.readthedocs.io/en/latest/doc/01.imageStart/imageStart.html hexo thema settinginit setting https://theme-next.org/docs/getting-started/ https://theme-next.iissnan.com/getting-started.html https://imsun.net/posts/gitment-introduction/ 안에 tag 넣고 주석 달고 하는거 연습 https://www.youtube.com/watch?time_continue=1&amp;v=I07XMi7MHd4 https://hexo.io/docs/front-matter.html#Categories-amp-Tags tag 추가 ,https://theme-next.org/docs/theme-settings/#Adding Google Calendar Page&gt; Adding «Categories» Page &lt;https://theme-next.org/docs/theme-settings/#Adding «Categories» Page&gt; 각종 Meta 추가 https://theme-next.org/docs/theme-settings/ https://theme-next.org/docs/third-party-services/comments-and-widgets/#Gitment 관련 참고 http://blog.lattecom.xyz/all-categories/ hexo next thema gitment setting다 해서 블로그에 다는거 까지 잘 됐는데 계속 오류남..[object ProgressEvent] gitment 보안 이거 너무 좋아보이는데 github은 api가 따로 없어서 일반 사용자가 직접 만들고 배포한 저 gitment를 쓰는거라 저 사용자가 oth 권한으로 내 git의 ment repo에 읽고 쓰기 권한이 자동으로 주어짐. (물론 프라이빗은 접근불가) 근데 또 내 yonsei university 학교계정으로 받은 각종 google drive 같은 것도 학교에서 맘대로 보고 쓰고 ㅡㅡ 아예 삭제까지 할 수 있는거 보단 내 퍼블릭 오픈된거 보고 쓸 수 있는거니.. 게다가 추적도 가능하니.. 쓰려했지만.. 자꾸 오류나서 포기.. 그리고 중국… 개발자에 홈피가 중국사이트라 그런건지 자꾸 내 크롬에서 보안경고 뜸.. 아마도 중국홈피에 내부 써드파티에 접속자 분석툴 같은게 google에서 인증 안된.. 거라 그런건가? 그냥 버리고 facebook sdk 로 감.. facebook은 전혀 안하는데 .. 그래서 안쓰려 한건데.. 어쩔 수 없지… 주석넣는거 연습.1Please note that the authorized permission of Gitment will obtain the read and write access to all your public repositories and maybe send github keys to the 3rd-party imsun&apos;s proxy server. If you concern about the security, we strongly deprecated to use gitment. Useful link npm i –save gitment https://github.com/imsun/gitment#get-started https://github.com/settings/applications/new Intersect - a CROS proxy https://github.com/aimingoo/intersect 동영상 넣는 것도 연습 ## blah blah blah blah blah blah blah blah blah ## ## Content (md partial supported) defaultprimarysuccessinfowarningdanger No icon noteNote without icon: note info no-icon 123code block in note tagcode block in note tagcode block in note tag No icon noteNote without icon: note info no-icon 123code block in note tagcode block in note tagcode block in note tag math testSimple inline $a = b + c$. $$\\frac{\\partial u}{\\partial t}= h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\\frac{\\partial^2 u}{\\partial y^2} +\\frac{\\partial^2 u}{\\partial z^2}\\right)$$ This equation $\\cos 2\\theta = \\cos^2 \\theta - \\sin^2 \\theta = 2 \\cos^2 \\theta - 1$ is inline. $$\\begin{aligned} \\dot{x} &amp; = \\sigma(y-x) \\\\ \\dot{y} &amp; = \\rho x - y - xz \\\\ \\dot{z} &amp; = -\\beta z + xy \\end{aligned}$$","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190116_TIL","slug":"20190116-TIL","date":"2019-01-15T17:28:27.000Z","updated":"2019-01-15T23:40:08.096Z","comments":true,"path":"2019/01/16/20190116-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/16/20190116-TIL/","excerpt":"","text":"참고 https://machinelearningmastery.com/transfer-learning-for-deep-learning/ 주피터 노트북 시작폴더 변경법https://code.i-harness.com/ko-kr/q/219f244 어제해야한거 오늘로 미룬거 부터.아래 코맨트 아직 미처리. This is in line with the comments in the saving section. You can recreate the model using model = getattr(models, arch)(pretrained=True) where arch is the architecture string. You would also need to recreate the classifier using nn.Sequential(), and the input, output, and hidden sizes. Your current code is using the previously defined classifier object, which isn’t saved in the checkpoint file, and would break your code if you attempted the load the model from the file without executing all your code above, which defeats the purpose of having a loading function, which should be usable by anyone having only access to the checkpoint file. 모델 선택할 때 나는 이런 느낌으로 다가 했는데 123456789101112if arch=='vgg19_bn': model = models.vgg19_bn(pretrained=True) model_nameprint = 'Default architecture : ' + archelif arch=='vgg13': model = models.vgg13(pretrained=True) model_nameprint = 'Selected architecture : ' + archelse: selected = 'models.'+ arch + '(pretrained=True)' model = selected model_nameprint = 'Selected architecture : ' + arch print(model) raise ValueError('Unexpected network architecture', arch) ## flag !!! 이거 말고 아래로 바꾸라고 함. Using model = getattr(models, arch)(pretrained=True)should load the proper model without the need for an if else statement Some information is missing from the saving code. You should save enough information to be able to reconstruct the model completely. You can save the architecture string, such as “vgg19”, and would need to save additional information such as input, and hidden size so that you can recreate the classifier as well. The goal is to be able to provide the checkpoint file to someone else and run the loading function to recreate your model completely Even though the plot and images are displayed properly, the names of the flowers are incorrect. To be able to get the correct names, you need to first reverse the class_to_to_idx dictionary, and use the topk labels as keys to get the correct class ids. Once you have the class ids, you can then use the class ids strings as keys in the cat_to_name dictionary to retrieve the correct class names. This is why you’re only getting 20-30% of the correct names even though your accuracy is close to 90%. You should be printing the training and validation loss during each epoch of training. Only the training loss is printed here. multiprocessing module 컴이 못따라가줘서 찾아보다보니 알게된 멀티프로세싱. 내 컴으로 cuda 사용시 gtx1050 2gb, 메모리 부족으로 큰건 돌릴 수 없음… 개별로 실행 잘 되는 건 확인 했는데, 실제 내가 사용하는 학습 알고리즘에 적용되는지 넣어보기. 참고. Deep Learning With PyTorch &ndash; Josh Bernhard &ndash; Medium 딥러닝 학습 기술들 &middot; ratsgo’s blog ‘Machine Learning/Theory’ 카테고리의 글 목록 :: UMBUM CS231n Convolutional Neural Networks for Visual Recognition umbum (umbum)","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190115_TIL","slug":"20190115-TIL","date":"2019-01-14T16:45:14.000Z","updated":"2019-01-15T17:46:15.980Z","comments":true,"path":"2019/01/15/20190115-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/15/20190115-TIL/","excerpt":"","text":"어제 끝내거나 아직인거(실은 미룬거) 자기 전 project2 제출 했는데 코멘트 옴. 메일 알람 듣고 자려고 누웠다가 일어나서 확인. 파일제출이 덜 되어 있어 다시 제출. 잠 깨는 바람에 컴터 켰는데. 인터넷 서핑중에 뜨는 창에 정말 맛있게 야식 비빔면 먹는거 보고 배속에서 꼬를르르륽. 새벽3시에 파썰어서 볶음밥….ㅠㅠㅠㅠ ㅠㅠㅠㅠㅠ 오늘 예정(제발 끝낼꺼) 한국어일기 쓰기 시작하자. 영어일기 쓰기 시작하자. 독일어일기 쓰기 시작하자. 중국어일기 쓰기 시작하자. 읭? 1 &gt; 2 &gt; 3 &gt; 4 : 우선순위 최소한 1에서 2까지 만이라도 … 3, 4는 예전에 자주 써버릇했었는데.. 지금은 일단 pass! 오늘 한 일(done!) install WaKatime Chrome, Visual Studio Code, PyCharm 엔 설치 잘 됐는데 Notepad++는 설치 오류. 안돼? 그럼 이젠 안쓸께. checking project2 comment. comment notebook으로 제출한 project는 정확도가 93%가 넘어갔기 때문에 칭찬 하지만 class_to_idx 및 idx_to_class를 사용하여 예측 시 class와 IDs의 이름을 올바르게 지정하라함. All import statements, including the ones provided by default, need to be moved to the first cell. This allows a quick look at all the project’s dependencies, and is a good programming practice. 완료 import를 to the first cell? 읭? 나 모두 그렇게 했는데? 확인해보니 json 불러올때 같이 import json 따로 내놓은게 유일한데 이것 때문인듯.. MNIST data 필기체 인식 코드 줄마다 코멘드 싹 다시 정리. 도저히 빵꾸가 많아서 이해가 안되고 외워졌던 부분 많이 매꿈. (여전히 많은 건 비밀) Module 직접 선언하기 그냥 이런 클래스 형식으로. 1234567891011121314class Network(nn.Module): def __init__(self): super().__init__() self.hidden = nn.Linear(784, 256) self.output = nn.Linear(256, 10) self.sigmoid = nn.Sigmoid() self.softmax = nn.Softmax(dim=1) def forward(self, x): x = self.hidden(x) x = self.sigmoid(x) x = self.output(x) x = self.softmax(x) return x activation function은 꼭 non-linear function 이어야함. 전단계 선형함수를 step이나 sigmoid, ReLu(rectified linear unit), TanH(hyperbolic tangent) 로 바꿔주기 위해. 다시 말하면 Yes or No 또는 1부터 10중에 뭐? 이런 식으로 나타내기 위해 비선형. 이런 의미겠지? 자주 보는 에러.12345678&gt;&gt; torch.mm(features, weights)# matrix multiplication---------------------------------------------------------------------------RuntimeError Traceback (most recent call last)&lt;ipython-input-13-15d592eb5279&gt; in &lt;module&gt;()----&gt; 1 torch.mm(features, weights)RuntimeError: size mismatch, m1: [1 x 5], m2: [1 x 5] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524590658547/work/aten/src/TH/generic/THTensorMath.c:2033 곱셈법칙에 의해 size mismatch, m1: [1 x 5], m2: [1 x 5] 가 발생. 앞 벡터 열과 뒤 벡터 행이 같아야 벡터곱이 가능한데 잘못됐기 떄문에 맞추기 위해 벡터성분 위치 조정. tensor에는 tensor.shape 이 있어서 조정할 수 있음. weights.reshape()weights.resize_()weights.view() weights.reshape(a, b) will return a new tensor with the same data as weights with size (a, b) sometimes, and sometimes a clone, as in it copies the data to another part of memory. weights.resize_(a, b) returns the same tensor with a different shape. However, if the new shape results in fewer elements than the original tensor, some elements will be removed from the tensor (but not from memory). If the new shape results in more elements than the original tensor, new elements will be uninitialized in memory. Here I should note that the underscore at the end of the method denotes that this method is performed in-place. Here is a great forum thread to read more about in-place operations in PyTorch. weights.view(a, b) will return a new tensor with the same data as weights with size (a, b). weights.view(5, 1) 로 바꿔서 해결. 근데 정방향으로 계산할 때랑 역방향으로 계산될 때 자동으로 바뀌게 하려고 view()쓴건주 알았는데 생각해보니까 한쪽이 고정이니 그것도 아니 잖아. 거꾸로 오면 아예 위치를 바꿔줘야하는데? view가 그것도 포함되어 있는 함수인건가? In my experience it’s more convenient to build the model with a log-softmax output using nn.LogSoftmax or F.log_softmax (documentation). Then you can get the actual probabilities by taking the exponential torch.exp(output). With a log-softmax output, you want to use the negative log likelihood loss, nn.NLLLoss (documentation). Exercise: Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss. Note that for nn.LogSoftmax and F.log_softmax you’ll need to set the dim keyword argument appropriately. dim=0 calculates softmax across the rows, so each column sums to 1, while dim=1 calculates across the columns so each row sums to 1. Think about what you want the output to be and choose dim appropriately. loss function 뭐 쓰는지에 따라 model끝단을 맞춰서 바꿔줘야 한다. 또 model 끝단에선 prameter값도 맞춰주어야함. LogSoftmax는 dim값 조정으로 행 대신 열로 계산하게 함. 현재시간 새벽 2시반. 빨리 자야….내일 또 밝은 하루가….!! model.forward(images)model.forward(images) 하는 이유.https://discuss.pytorch.org/t/potential-solution-to-different-forward-for-train-and-inference-ide-support-for-forward-args/33756","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190114_TIL","slug":"20190114-TIL","date":"2019-01-14T03:42:04.000Z","updated":"2019-01-15T06:34:33.713Z","comments":true,"path":"2019/01/14/20190114-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/14/20190114-TIL/","excerpt":"","text":"영어는 언제할꺼임? 일단 오늘 현재까지 한 일 Video program setting done Python Argpare 이것저것 실험해보기. 각각 parameters, argument 비교해보기 https://pymotw.com/3/argparse/ https://docs.python.org/3/library/argparse.html#action github sync 다시 맞추기 100MB 이상되는 파일 껴있을때 해결법 찾기 설정값 조절하라는데 해도 안됨. 100MB 넘는 파일 밖으로 뺴냈는데도 이미 들어간 파일이라 history에 올라가버려니 결국 오류 ignore값 설정해도 이미 그전 history에 먼저 올라가있어 안됨. history revert 하면 컴퓨터에 파일들이 아예 과거로 회귀해버림.. github network에 repo 삭제 -&gt; repo ADD 숨긴파일로 .git history 저장되어 있어서 예전과 같은 상황 발생. github network에 repo 삭제 -&gt; repo Create 아예 그냥 삭제후 다시 만듬. github에 올라있는 이전 파일들 그냥 강제삭제.. 이 방법 밖에는 없는 걸까? Project submission : Udacity Data Scientist Nanodegree Project 2 : Create Your Own Image Classifier 102가지 꽃 종류 판단하기 4일동안 하루~~종일 고치고 실행하고 고치고 실행.. CUDA 없이 그냥 Scikit-learn으로 해볼 때는 수정하고 고치고가 쉬웠고 frontforward, backpropagation 모두 쉽게 예측(?) 해볼 수 있었다. pythorch로 CUDA ON 하고 사용할 때 명령어도 싹 바뀌었고 model parameter 솎아내고 수정하는거, 그리고 argument 설정하는 것들… 고생 좀 했다. vgg19_bn에 linear 1개 더 추가해서 돌렸더니 정확도가 93%까지 올라갔는데 실제 테스트할 때는 도대체가 맞지를 않는다. 너무 올래걸리기도 하고(내 컴 GTX1050 2GB) 내 컴으론 도저히 뭘 할 수가 없어 Udacity 가상머신 GPU 켜놓고, 진행 vgg13으로 linear는 다시 기본으로 input-hidden(512)-output, bath_size=32 로 해서 돌리는데 정확도 67%. 60 넘었으니 일단 pass. 마찬가지.. 이미지 가지고 checking 하는데 자꾸 틀린다…. 왜 그러지? 이것 때문에 이틀 더 걸렸는데… 그래서 그냥 냄…. 그래서 Advisor 에게 멋진 코멘트도 씀.. dear Advisor, please, lead me the right way.. 직역하면 올바른 길로 인도해주세요.. 제바알~~ 123456789101112131415Dear Advisor,1. Development Notebookwhen using Notebook(vgg19_bn) , the accuracy went up 93%, but when check real image, the results were constantly wrong. It&apos;s almost a 20%? 30%? probability.2. Command Line ApplicationLikewise, when check real random image, the results were constantly wrong. I really hope I can fix it. I&apos;ve tried a lot, but i don&apos;t know what to do, where wrong, how fix.please give me a some hint, and lead me the right way.Thank you and Happy new year! 현재시간 오후 10시. 영어는 결국? 59.4 내일 할일 영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어영어 제발 좀. 영어.","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190113_TIL","slug":"20190113-TIL","date":"2019-01-12T16:01:57.000Z","updated":"2019-01-13T16:17:19.376Z","comments":true,"path":"2019/01/13/20190113-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/13/20190113-TIL/","excerpt":"","text":"argparsehttps://docs.python.org/2/library/argparse.html 15.4.3. The add_argument() method 1ArgumentParser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest]) Define how a single command-line argument should be parsed. Each parameter has its own more detailed description below, but in short they are: name or flags - Either a name or a list of option strings, e.g. foo or -f, –foo. action - The basic type of action to be taken when this argument is encountered at the command line. nargs - The number of command-line arguments that should be consumed. const - A constant value required by some action and nargs selections. default - The value produced if the argument is absent from the command line. type - The type to which the command-line argument should be converted. choices - A container of the allowable values for the argument. required - Whether or not the command-line option may be omitted (optionals only). help - A brief description of what the argument does. metavar - A name for the argument in usage messages. dest - The name of the attribute to be added to the object returned by parse_args(). The following sections describe how each of these are used. https://docs.python.org/3/library/argparse.html https://pymotw.com/3/argparse/ TORCH.OPTIMhttps://pytorch.org/docs/stable/optim.html HOW TO ADJUST LEARNING RATEhttps://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate 12345678&gt;&gt;&gt; # Assuming optimizer has two groups.&gt;&gt;&gt; lambda1 = lambda epoch: epoch // 30&gt;&gt;&gt; lambda2 = lambda epoch: 0.95 ** epoch&gt;&gt;&gt; scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2])&gt;&gt;&gt; for epoch in range(100):&gt;&gt;&gt; scheduler.step()&gt;&gt;&gt; train(...)&gt;&gt;&gt; validate(...) 12345678910&gt;&gt;&gt; # Assuming optimizer uses lr = 0.05 for all groups&gt;&gt;&gt; # lr = 0.05 if epoch &lt; 30&gt;&gt;&gt; # lr = 0.005 if 30 &lt;= epoch &lt; 60&gt;&gt;&gt; # lr = 0.0005 if 60 &lt;= epoch &lt; 90&gt;&gt;&gt; # ...&gt;&gt;&gt; scheduler = StepLR(optimizer, step_size=30, gamma=0.1)&gt;&gt;&gt; for epoch in range(100):&gt;&gt;&gt; scheduler.step()&gt;&gt;&gt; train(...)&gt;&gt;&gt; validate(...) 설치 http://bob3rdnewbie.tistory.com/313https://pytorch.org/get-started/locally/ [Window Title]Python [Main Instruction]Python의 작동이 중지되었습니다. [Content]문제에 대한 해결 방법을 확인하는 중입니다. [취소] https://tensorflow.blog/2018/04/25/pytorch-0-4-0-release/https://tensorflow.blog/2018/04/25/pytorch-0-4-0-release/ https://github.com/tensorflow/tensorflow/issues/22794conda create –name tf-gpuconda install -c aaronzs tensorflow-gpuconda install -c anaconda cudatoolkitconda install -c anaconda cudnnconda install keras-gpu https://github.com/pytorch/pytorch/issues/4518from torch._C import * (ImportError: DLL load failed: The specified module could not be found. https://pytorch.org/docs/stable/torch.html#torch.topk","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"20190112_TIL","slug":"20190112-TIL","date":"2019-01-12T06:51:29.000Z","updated":"2019-01-12T08:00:04.044Z","comments":true,"path":"2019/01/12/20190112-TIL/","link":"","permalink":"http://namwoo.github.io/2019/01/12/20190112-TIL/","excerpt":"","text":"TIL. 올라라 정확도야.새벽 6시까지 진행중인거 보다 잠듬. VGG19_BN 모델 batch size 조정12batch size=8num_workers=2 엄청~ 나게 오래걸림. 정확도도 너무 낮음.. 12batch size=32num_workers=0 더 빨라졌는데 정확도가 70프로대가 한계.. 12batch size=64num_workers=0 다시 계산중인데 확실히 빠르고 현재 93프로까지 정확도가 상승","categories":[],"tags":[{"name":"TIL","slug":"TIL","permalink":"http://namwoo.github.io/tags/TIL/"}]},{"title":"TILStart","slug":"TILStart","date":"2019-01-11T06:15:30.000Z","updated":"2019-01-12T07:58:16.057Z","comments":true,"path":"2019/01/11/TILStart/","link":"","permalink":"http://namwoo.github.io/2019/01/11/TILStart/","excerpt":"","text":"intro어릴 때부터 끄적끄적 적어놓는걸 좋아했다. 이곳저곳 교과서 귓퉁이부터 포스트잇, 종이쪼가리 어디든 보이는 곳에다가. 스마트폰을 사용하면서 자연스럽게 구글캘린더와 에버노트, 몇가지 아기자기한 어플들을 사용해서 수년을 적었는데 에버노트 유료라서 안쓰게 되고 어플들은 휴대폰 초기화나 교체 중에 백업파일 오류로 몇년짜리 자료가 날라가면서 의욕도 사라지고 고정 활동들을 안하게 되면서 매번 하던걸 안해도 되어버리니 자연스럽게 최근에는 그 빼곡히 채우던 즐거움이 사라졌다. 몇개의 컴퓨터와 휴대기기들을 쓰다보니까 연동문제도 그렇고 유료문제도 걸려있어서 더욱 … 어쨌거나 저쨌거나 다시 정리하기로 마음 먹었으니 일기로 또는 개발일지로 또는 반성일지로 활용하면서 꾸준히 쌓아보자. 페이스북, 인스타그램, 블로그를 전혀 안해오고 하는 법도 모르지만… 이것 만큼은 꼭 꾸준히 나를 위해서. 내 미래를 위해서. 해보자. 뭔가를 쓸 때 나름의 성취욕? 성과욕? 이 있으면 좋을 것 같아 지금 github에 contributions 처럼 2014년도에 있는 단 1건의 나의 contribution… 이렇게 시각화, 시각적, 비주얼적으로다가 그래프와 도표 등을 활용해서 약간 PM처럼.. agile? waterfall? 뭐랄까 그런 그림적인 느낌적인 느낌으로다가 작성을 해보려한다. 그리고 모든 것들을 당일 저녁 12시 이전에 꼭 push! goal OneNote 컴퓨터간 휴대기기간 싱크 맞추기 계정 통합, 정리, 이동 OneNote와 Github sync 확인 Google Google Calendar sync Google Timeline sync Evernote에 있는 과거정리내용 옮길건 옮기기 예전 어플들 backup 내용 확인, 정리 시각화를 어떻게 하면 좋을지 찾아보기 TILPEP 8Python Enhancement Proposalshttps://www.python.org/dev/peps/#introduction PEP 8Style Guide for Python Codehttps://www.python.org/dev/peps/pep-0008/ 오늘 찾은 위의 정보나 내용을 어떻게 넣을지 확인 diary life info 관심?관심, 흥미 잠깐 눈이 갔었던.. 것들은 영어표현을 어떻게 해야하나..? 거기서 조금 더 관심이 가 깨작 거리는 것들은 또 어떻게 표현하는게 맞으려나? done일단 형태만 갖추기. 주소줄이기https://goo.gl/ 듣고 있는, 들으려는, 들었던 강의 정리(Google Docs)https://goo.gl/c3T37m 읽고 있는, 읽으려는, 읽었던 책 정리(Goole Docs)https://goo.gl/rJcKLv 오늘의 TILBatch Size in Deep Learning 참고 https://blog.naver.com/wideeyed/221425994244 https://blog.lunit.io/2018/08/03/batch-size-in-deep-learning/ 몇 가지 parameter를 조정하면서 Accuracy 향상을 노려보고 있는데 아직 초심자 입장에서 각각의 배포되는 Docs를 보면 너무 다양하고 많은 parameter가 있어서 이번에 몇가지를 건드려봤다. 물론 실제 산업에서 어떻게 이용, 응용, 사용되는지를 모르고 있으니 이게 맞는지도 모르겠고 그렇다고 parameter 조정 논문들을 다 뒤져볼 수도(당장) 없으니 일단 하나씩… 공부할 때 batch size 라는 개념은 나는 bit로 생각했다. 쉽게 컴퓨터가 단일, 1개의 라인으로 처리하는게 아니라 병렬로 64개의 줄을 만들어 처리한다고 이해했다. 높을 수록 속도가 빠르고 빠른만큼 놓치는 부분들로 인해 오류값이 올라간다. 정도? 그래서 알아보기 시작했다. Recall: Stochastic Gradient Descent (SGD)loss function를 줄이기 위해 Gradient Descent로 backpropagate와 frontforward를 반복하는건 알고 있다. 그리고 계산량이 많아질 수 있어서 전체 데이터가 아닌 random 데이터로 추려내서 계산하고 있는 방법도 알고 있었다. 또 최소가 되는 점을 찾다가 local mininum이 발생할 수 있어서 momentum, 가중치로 예전값일 수록 $\\beta$ 값을 상대적으로 작게, 최근값은 크게 주는 것도 알고 있다. 그럼 도대체 batch size란? Stochastic Gradient Descent는 전체 데이터에 대해 엄청난 계산량을 줄이고자 한 반복횟수에 하나의 examle만 사용하는 방법이다. 이 경우 추정된 Gradient 값이 너무 noise 해진다는 단점이 있어 이 방법을 보완하기 위해 매 횟수마다 적당한 크기의 mini-batch에 대한 Gradient를 사용하는 Mini-Batch Stochastic Gradient Descent (SGD)이며 딥러닝에서 가장 일반적으로 사용되는 기법 이라 한다고 한다. 이때 나오는 batch size가 클수록 Gradient가 정확해지지만 한 반복에 계산량이 늘어나고 …. ?? 모르겠다. 어쨌든 batch size가 높으면 빠르다. batch size가 낮으면 속도가 느리다. (high variance) 모델마다 상황에 맞는, 가장 높은 정확도를 나타내는 batch size가 있다.","categories":[],"tags":[{"name":"TIL, Diary","slug":"TIL-Diary","permalink":"http://namwoo.github.io/tags/TIL-Diary/"}]},{"title":"whatastupidday","slug":"whatastupidday","date":"2018-12-30T07:34:28.000Z","updated":"2018-12-30T08:35:51.893Z","comments":true,"path":"2018/12/30/whatastupidday/","link":"","permalink":"http://namwoo.github.io/2018/12/30/whatastupidday/","excerpt":"","text":"두 달 전부터 써오고 준비했던, 누구보다 미리미리 준비하고 써왔던 원서를 제출 못했다30분 전에 제출하려고 보니 pdf 를 올리는 게 아니고 그걸 또 나눠서 올려야 하는 거였고 파일명을 한국어를 빼고 하길 권고 하길래 혹시 몰라 또 파일명을 일일이 바꿔주었고 그렇게 들어갔더니 결제.. 결제과정에 설치하고 가상계좌를 받니 뭐하니 넘어가고 결제는 휴대폰 계좌이체로 진행보안카드 입력 중 2회오류.ㅡㅡ 분명 똑같이 눌렀는데도 오류..3번째 오류면 대참사이니 마지막 기회라고 천천히 눌러서 버튼을 누른 순간 마감시간 오후 5시1분에 1초가 넘어가버려 계좌이체 실패….. 나 같은 바보가 또 있을까?전화했더니 나 같은 사람이 또 많았나 보다. 묻고 따지고 듣지도 않고 무조건 안된단다. ‘아니 혹시 시스템 상에 오류가 있을 수도 있으니 확인해주시면 안될까요?’ 내가 하는 말이 끝나기도 전에 안된단다. 나 스스로 본인에게 화나고 이런 나에게 대처하는 직원에게 화나고 하지만 멍청한 내 자신에 더 어의없고.. 이제 1년을 기다려야하네? ………. 안녕.. 너랑은 인연이 없나보다.","categories":[],"tags":[]},{"title":"scholarship","slug":"scholarship","date":"2018-12-24T06:01:47.000Z","updated":"2018-12-24T06:01:47.482Z","comments":true,"path":"2018/12/24/scholarship/","link":"","permalink":"http://namwoo.github.io/2018/12/24/scholarship/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"car_accident_almost","slug":"car-accident-almost","date":"2018-12-24T01:06:06.000Z","updated":"2018-12-24T06:08:16.082Z","comments":true,"path":"2018/12/24/car-accident-almost/","link":"","permalink":"http://namwoo.github.io/2018/12/24/car-accident-almost/","excerpt":"","text":"끌어오르는 분노를 억누르며 집으로 들어와 랩탑으로 네비영상을 뽑아 컴으로 다시 확인하니 다시 솓구친다. 분노가. 월요일이면 거의 하루에 운전만 많게는 6시간. 최소 3시간반? 하는 날이다. 오늘도 어김없이 70km 떨어진 곳에 동생을 내려주고 다시 돌려 집으로 돌아오는 길에 구형 똥빠리색 마티즈가 자기 차로는 고속도로로 빠지는 곳이니 급차선 변경으로 내 바로 앞으로 끼어든다. 깜빡이도 없이… 저런 분 많지. 그래.. 내가 조심해야지.. 하면서 고속도로에서 빠지는 방향으로 미리미리 들어와서 미리미리 속도 줄이고(바닥에 빨간라인 따라) 유유히 나가는데 옆차선에서 또 깜빡이도 없이.. 끼어들지 말라고 하옇고 굵게 거북이 등껍질처럼 V표 좍좍 그려논 곳을 뚫고 내 앞을 가로막는다. 근데 영상을 다시 보면서 느끼는 거지만 확실히 내가 직접 운전할 때 느꼈던 그 긴장감? 사고나기 직전 그 쫄깃한 상황? 그건 잘 느껴지지 않지만 실제론 엄청 위험했고 훨씬 가까웠으며 엄청 놀랐던 그 상황… 놀래서 빵도 못하고 …미안한지 뒤에서 깜빡이 켜주던데.. 그럼 뭐해..그렇게 해서 사고나면.. 내 과실도 전방부주의 땡겨 갈꺼면서..어휴..","categories":[],"tags":[]},{"title":"algolia","slug":"algolia","date":"2018-12-19T05:46:41.000Z","updated":"2018-12-19T07:02:23.603Z","comments":true,"path":"2018/12/19/algolia/","link":"","permalink":"http://namwoo.github.io/2018/12/19/algolia/","excerpt":"","text":"정신없는 몇 주. 강의도 끝내야 했고 과제도 시험도 도와줘야 했고 또 오래걸리고 힘들었던 프로젝트를 진행하면서 수업시간에 배웠던 내용들도 복습해야 했고 그걸 가지고 kaggle에 competition도 해봤다. (17위!! 참가자가 별로 없다는게 비밀) 그리고 나서 뻐근한 어께도 풀어줄겸 쉬엄쉬엄(?) 블로그를 떠돌다가 algolia라는 검색엔진? 검색분석엔진? 을 찾고 내 블로그에도 적용해보기 위해 빨래 2번 돌릴 시간 동안(드럼세탁기 삶음기능 2번) 이리저리 시도해봤다. Register at Algolia 가입 그리고 알고리아가 뭔지 확인 https://www.algolia.com/첫 가입 후 14일 후면 FREE모드로 넘어가서 한달에 up to 10k records and 100k operations per month.확인은 빌링탭 가입 후 dashboard 탭에 보면 왼쪽 사이드탭에 Indices 눌러서index 버튼 왼쪽에 이름 눌러서Create index이름은 원하는데로. 나는 원래 깃헙 블로그파일명인 myBlog 또 다시 왼쪽 사이드탭에API Keys를 눌러보면 Your API Keys 탭에 있는 정보 Application ID = 블라블라 Search-Only API Key = 블라블라 이 두 개를 잘 기억 그리고 github 블로그에 테마가 설치되어 있는 원래 기본적으로 블로그에 사용하던 폴더로 이동해서 123npm install --save hexo-algolianpm i hexo-generator-json-content --savenpm i --save hexo-wordcount git 설정 _config.yml 추가 12345algolia: applicationID: 기억해놓은 Application ID 블라블라 입력 apiKey: 역시 기억해놓은 Search-Only API Key 블라블라 입력 indexName: 아까 Create index로 만든 이름 입력 chunkSize: 5000 그리고 테마 설정 _config.ymlalgolia_search 값을 true로 123456789# Algolia Searchalgolia_search: enable: true hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: \"We didn't find any results for the search: $&#123;query&#125;\" hits_stats: \"$&#123;hits&#125; results found in $&#123;time&#125; ms\" 그리고 윈도우os 일 경우실행-cmd에서1set HEXO_ALGOLIA_INDEXING_KEY=Search-Only API key # Use Windows command line 맥이라면1$ export HEXO_ALGOLIA_INDEXING_KEY=Search-Only API key # Use Git Bash 환경변수값 설정하는건데 직접 윈도우 성능에 고급, 환경변수 들어가서 추가했더니 안됨. 위 쓴데로 하는게 더 쉬움. 다 되면12$ hexo clean $ hexo algolia 그리고 잘 적용됐는지 12$ hexo generator$ hexo deploy 급 생각난 현주누나의 명언 출처https://github.com/algoliahttps://www.npmjs.com/package/hexo-algolia#api-keyhttps://github.com/theme-next/hexo-theme-next/blob/master/docs/ALGOLIA-SEARCH.mdhttps://zouzeir.xyz/2017/01/16/Hexo%E9%9B%86%E6%88%90Algolia%E6%90%9C%E7%B4%A2%E6%8F%92%E4%BB%B6/https://elfinlas.github.io/2018/06/07/hexo-usea-lgolia/","categories":[],"tags":[]},{"title":"tree","slug":"tree","date":"2018-12-10T23:27:27.000Z","updated":"2018-12-10T23:50:41.362Z","comments":true,"path":"2018/12/11/tree/","link":"","permalink":"http://namwoo.github.io/2018/12/11/tree/","excerpt":"","text":"올해도 이뻐보이네. 설명회가 있어서 가뜩이나 복잡해진 금요일 저녁 신촌이기에 미리미리 가있으려 했지만.. 역시 꼼지락 거리다 늦장 부리기도 했고..부랴부랴 뛰어서 시간 맞춰서 간신히 도착했으나…. 경영관에서는 대우관으로요.대우관에서는 경영관으로요.잉? 대우관 별관 가봤더니 대우관으로요.읭? 경영관 같은데요? 인터넷 다른 모든 글에는 경영관이었는데 공지 설명글 마지막에 대우관. 결과적으로 대우관은 나중에 저기서 강의하겠다는 내용이었고또 오늘이 아닌 다음주에 진행하는 거였기 때문에 아무도 없었던 ….. 올해가 끝나가기 전에도 바보짓 하는 바보 같은 나의 행동에 감탄하며집에가려고 경영관 중앙 엘레베이터를 탔는데 (통유리라 사방이 잘보임, 그리고 나 혼자)바로 밑에 층에서 직원이라기엔 어리고 대학원생 처럼 보이는 여자분 한 분이 타자마자트름을..꺼억.. 일반적인 소리 큰 트름이 아닌, 속에서 기 모아 올라오는 소리 적고 내용 가득 담은 그 트름을. ㅡㅡ 가뜩이나 바보 같은 짓 한 나 더 정신차리라고 맡으라고 쏟아내신 거겠지.. 암 난 혼나야지.. 그렇게 나오는데 트리에 불이 환한거 보고 나는 바보 같지만 저건 이뻐서 찰칵.","categories":[],"tags":[{"name":"연세대, yonsei university","slug":"연세대-yonsei-university","permalink":"http://namwoo.github.io/tags/연세대-yonsei-university/"}]},{"title":"things","slug":"things","date":"2018-12-06T01:11:35.000Z","updated":"2018-12-06T01:13:23.762Z","comments":true,"path":"2018/12/06/things/","link":"","permalink":"http://namwoo.github.io/2018/12/06/things/","excerpt":"","text":"해야 할 것들이 너무 많어..하고 싶은 것들도 너무 많어..시간은 너무 빨리가고 있고..나이는 한 살씩 늘어나는데머리 속은 채워지지 못하는 이 느낌","categories":[],"tags":[]},{"title":"대학원 알아보기(1)","slug":"MD1","date":"2018-12-05T00:43:33.000Z","updated":"2018-12-05T00:46:11.156Z","comments":true,"path":"2018/12/05/MD1/","link":"","permalink":"http://namwoo.github.io/2018/12/05/MD1/","excerpt":"","text":"첫 깃헙블로그 테스팅 3번째 글.깃헙에서 그리고 내 로컬에서 잘 올리고 받고 확인도 되었는데한글이 깨지길래 이것저것 업뎃하니까 잘 되길래 봤더니 또 깨지네..지금 이 글은 안깨지고 있으려나..? Master Degree, Graduate School 을 알아보면서 정리도 할겸거기다가 github 공부도 할겸 알아가보자 why do I need a degree?각종 MOOC 를 들으면서 nanodegree도 따고 specialization도 계속 따고 있고이리저리 더 공부해보다보니 배움이 더 고파진다.온라인엔 전세계에 내노라 하는 석학들의 무료오픈소스 수업들이 널리고 널렸다.amr chiar scholar 인 나에겐 너무너무 좋은 분들.. 온라인의 장점을 최대한 챙기면서오프라인의 강점을 살리기 위해선 대학원은 필수인거 같아 알아보게 되었다. conditional statement: tuition : 학비가 감당할 정도여야 할 것. 그래봤자 어차피 학자금 대출. 통학, 교통, 숙식. 가진거 없이 학자금 대출로 공부하는거니 최대한 아낄 수 있어야 한다는 점. 해외든 어디든 상관없이 배울 수 있고 스스로 성장할 수 있다면 최우선으로! keywords: Data analyst, Data Science, Data Engineering 이럴꺼면 산업대학원, 일하면서 석사 따는게 더 좋아보이기도 했는데..후자는 확실한 길이 보이지 않았고 모자란 내 짱구로 생각해본 결과…경제 상황 상, 취업 구직난 상으로 볼 때 신입이 성장하기 힘들어보일거 같다는 뇌피셜.로 패쓰. in China중국.. 내수가 짱짱한 나라니 중국어 잘하면 한국오지말고 세계 어디에서든지 생활하면 참 좋을거라는건 누가 말하주지 않아도 중국에서 고등학교를 다녀본 조기유학을 통해 느껴보았고, 중국에서 그 친구들이 지금까지 살고 있는 20년, 아니지 부모님부터 자녀까지 중국에서 거주하고 있는 친구들이 주변에 많이 있다보니 중국은 항상 눈독드리는 나라. if (in China)also if (Chinese and English languages) than ok. 중국에선 중국어만 해서는 안된다. 학위만 따올거라면 모르겠는데 취업까지 넘어가려면 돈 많고 능력 뛰어난 American Chinese 같은 친구들이 너무너무너무너무너무 많다. 북대, 칭화대 애들….. 중국 수십억명중에서 뽑히고 뽑히고 뽑힌 애들을 따라갈 수는 없다.. 언어를 잘해야 어떻게 말이라도 붙여보고 배울텐데 언어도 못하면서 공부하겠다면.. 언어배우다 시간만 낭비할께 뻔한 상황.. 이건 미국, 독일, 일본 어디든 마찬가지.. 거기다 조선족.. 요즘 조선족분들… 예전엔 중국에서 한국어가 들리면 조선족과 한국인을 구별하는건 너무너무 쉬웠다. 일본인, 한국인, 중국인 구별하는 것도 너무 쉬웠고.근데 요즘은 옷, 행동, 말습관 모두 너무 비스므리해지고 체형도 많이 또 바뀌고..아직 외모적으로는 차이가 나는게 보이지만한국에 있는, 전문직종에 일하는 조선족들은 와…. 한국인보다 한국말도 잘하고 죄다 엘리트.. 중국에서 중국어 가르쳐주시던 조선족 과외선생님이 계셨는데그분은 중국어, 한국어 에다가 일본어, 영어까지……어차피 중국어랑 한국어는 기본이고 교육과정상 영어는 또 당연히 할 수 있고..취미로 일본어 하나 더 하면 이미….4개 국어..이쪽 언어들은 유럽애들처럼 언어학적으로 비스므리해서 독일프랑스 애들 모이면 대충 50% 이해하고 넘어가는 것도 아닌데 이미 4개국어..출발선부터 다른.. 분들과 경쟁하려면 나도 나만의 경쟁력을 길러야하기에.. 한국 돌아오면 비벼볼 수는 있다.워낙 한국에 적을두고 해외를 갔다오면 한국에서 그래도 어느 기준으로 공부를 했구나라는게 눈치껏 보인다.돈으로 해외대학가서 언어만 잘해오는 해외파들이 넘쳐나기에 그 사람들보다 경쟁력있으려면 언어는 못할지라도 실력으로 밀어야…. (실력만 가지고 안되는게 세상이던데..) 다시 돌아와서.beijing 아니면 shanghai, hongkong 쪽인데 Tsinghua University 쪽은 이거 3개 Tsinghua-UC Berkeley Shenzhen InstituteData Science and Information Technology (M)(ED) Global Innovation eXchange Institute,Tsinghua UniversityData Science and Information Technology (M) Graduate School at Shenzhen，Tsinghua UniversityData Science and Information Technology (M) 홍콩 쪽, 상해 쪽은 뒤에 이어서… 대학원 알아보기(2) 어디든 들어가서 열심히 공부, 최선을 다해 노력 만 가지고는 복잡한 세상 편하게 살 수 없어졌고어딜가나 해외는 수 많은 네이티브들과 경쟁해야 할텐데 영어랑 로컬, 그리고 추가외국어까지.. 그리고 당연히 실력까지 있어야 하니 전략적 잘 접근해야 요즘 같은 때에 살아남고 먼 훗날을 도모할 수 있으리니..","categories":[],"tags":[{"name":"master degree","slug":"master-degree","permalink":"http://namwoo.github.io/tags/master-degree/"}]},{"title":"post","slug":"post","date":"2018-12-04T16:06:06.000Z","updated":"2018-12-04T16:08:53.231Z","comments":true,"path":"2018/12/05/post/","link":"","permalink":"http://namwoo.github.io/2018/12/05/post/","excerpt":"","text":"�� ������ Ȯ��Ȯ��","categories":[],"tags":[]},{"title":"first-post","slug":"hello-world","date":"2018-12-04T10:24:17.964Z","updated":"2018-12-05T00:47:19.459Z","comments":true,"path":"2018/12/04/hello-world/","link":"","permalink":"http://namwoo.github.io/2018/12/04/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.�׽�Ʈ�׽�Ʈ�ѱ��� �Ƚ��� Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing�׽�Ʈ�׽�Ʈ Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}